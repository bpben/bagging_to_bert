{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280c2486-cf28-4e32-9b85-3caf4296a3f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b.batorsky/.conda/envs/spacy/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13eb78f4-b61c-4e56-a1e2-153fb0482523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cfc03-000a-4381-a353-2778f97b2a36",
   "metadata": {},
   "source": [
    "## Bagging to BERT: A tour of applied NLP\n",
    "### Part 1: Four flavors of bagging\n",
    "### Table of Contents\n",
    "* [Data processing](#data)\n",
    "* [Word Counts](#word)\n",
    "* [TF-IDF](#tfidf)\n",
    "* [Topic models](#topic)\n",
    "* [Word vectors](#vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7e591-7d7b-4d92-8f61-d5bb03af5dd7",
   "metadata": {},
   "source": [
    "### Data processing <a class=\"anchor\" id=\"data\"></a>\n",
    "\n",
    "Up first is some preprocessing.  You'll either need to download the [imdb review data](https://ai.stanford.edu/~amaas/data/sentiment/) and save it to this directory OR download the [processed data](https://drive.google.com/file/d/1oN_fO91IBkDHD_u6WXiUCvhhyNexQDJq/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3c4ac0-5a90-49ef-b03b-378932d13c9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # processing the original data into DataFrame\n",
    "# # here for reference, don't need to run this if you're using reviews.pkl.gz\n",
    "# source_path = Path('./aclImdb/')\n",
    "# #neg_files = source_path.glob('./*/neg/*.txt')\n",
    "# #pos_files = source_path.glob('./*/pos/*.txt')\n",
    "# all_files = []\n",
    "# for f in source_path.glob('./*/*/*.txt'):\n",
    "#     filename = f.as_posix()\n",
    "#     if 'unsup' not in filename:\n",
    "#         # split up into useful components\n",
    "#         _, split, sent, idx = filename.split('/')\n",
    "#         idx = int(idx.split('_')[0])\n",
    "#         all_files.append([idx, split, sent, f.read_text()])\n",
    "# review_df = pd.DataFrame(all_files)\n",
    "# review_df.columns = ['idx', 'split', 'label', 'text']\n",
    "# # some minor html cruft is in here\n",
    "# review_df['text'] = review_df['text'].str.replace('<br /><br />', '')\n",
    "# review_df = review_df.to_pickle('reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28f61ea-8e62-4d21-8f5a-6e3eb1bed2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can skip here if you already have reviews.pkl.gz\n",
    "review_df = pd.read_pickle('reviews.pkl.gz')\n",
    "review_df['label'] = review_df['label'] == 'pos'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db840c0f-9f6d-4058-9913-356eb700dcd0",
   "metadata": {},
   "source": [
    "### Word counts  <a class=\"anchor\" id=\"data\"></a>\n",
    "A very basic way to use a sanitized list of tokens is to do a word count. This unlocks a lot of insights right off and is an important step in exploratory data analysis in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2646a7d-b0f4-406d-bb68-7f5351b425b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n",
      " Alan Rickman & Emma Thompson give good performances with southern/New Orleans accents in this detective flick. It's worth seeing for their scenes- and Rickman's scene with Hal Holbrook. These three actors mannage to entertain us no matter what the movie, it seems. The plot for the movie shows potential, but one gets the impression in watching the film that it was not pulled off as well as it could have been. The fact that it is cluttered by a rather uninteresting subplot and mostly uninteresting kidnappers really muddles things. The movie is worth a view- if for nothing more than entertaining performances by Rickman, Thompson, and Holbrook. \n",
      "\n",
      "Positive\n",
      " Based on an actual story, John Boorman shows the struggle of an American doctor, whose husband and son were murdered and she was continually plagued with her loss. A holiday to Burma with her sister seemed like a good idea to get away from it all, but when her passport was stolen in Rangoon, she could not leave the country with her sister, and was forced to stay back until she could get I.D. papers from the American embassy. To fill in a day before she could fly out, she took a trip into the countryside with a tour guide. \"I tried finding something in those stone statues, but nothing stirred in me. I was stone myself.\" Suddenly all hell broke loose and she was caught in a political revolt. Just when it looked like she had escaped and safely boarded a train, she saw her tour guide get beaten and shot. In a split second she decided to jump from the moving train and try to rescue him, with no thought of herself. Continually her life was in danger. Here is a woman who demonstrated spontaneous, selfless charity, risking her life to save another. Patricia Arquette is beautiful, and not just to look at; she has a beautiful heart. This is an unforgettable story. \"We are taught that suffering is the one promise that life always keeps.\"\n"
     ]
    }
   ],
   "source": [
    "# take a positive and negative review for examples\n",
    "neg_review = review_df.loc[~review_df.label].iloc[0]['text']\n",
    "pos_review = review_df[review_df.label].iloc[0]['text']\n",
    "print('Negative\\n', neg_review, '\\n')\n",
    "print('Positive\\n', pos_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee60e2b-b1b5-4342-9e7e-8e0e3f17538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 4, 'it': 4, 'for': 3, 'and': 3, 'The': 3, 'performances': 2, 'with': 2, 'in': 2, 'worth': 2, 'Holbrook.': 2, 'movie': 2, 'that': 2, 'as': 2, 'is': 2, 'by': 2, 'a': 2, 'uninteresting': 2, 'Alan': 1, 'Rickman': 1, '&': 1, 'Emma': 1, 'Thompson': 1, 'give': 1, 'good': 1, 'southern/New': 1, 'Orleans': 1, 'accents': 1, 'this': 1, 'detective': 1, 'flick.': 1, \"It's\": 1, 'seeing': 1, 'their': 1, 'scenes-': 1, \"Rickman's\": 1, 'scene': 1, 'Hal': 1, 'These': 1, 'three': 1, 'actors': 1, 'mannage': 1, 'to': 1, 'entertain': 1, 'us': 1, 'no': 1, 'matter': 1, 'what': 1, 'movie,': 1, 'seems.': 1, 'plot': 1, 'shows': 1, 'potential,': 1, 'but': 1, 'one': 1, 'gets': 1, 'impression': 1, 'watching': 1, 'film': 1, 'was': 1, 'not': 1, 'pulled': 1, 'off': 1, 'well': 1, 'could': 1, 'have': 1, 'been.': 1, 'fact': 1, 'cluttered': 1, 'rather': 1, 'subplot': 1, 'mostly': 1, 'kidnappers': 1, 'really': 1, 'muddles': 1, 'things.': 1, 'view-': 1, 'if': 1, 'nothing': 1, 'more': 1, 'than': 1, 'entertaining': 1, 'Rickman,': 1, 'Thompson,': 1})\n"
     ]
    }
   ],
   "source": [
    "# base python word count - split on whitespace, use Counter object)\n",
    "print(Counter(neg_review.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c7f82-7e21-42a1-9f70-0c97345ab36a",
   "metadata": {},
   "source": [
    "Already see some things that need to be considered; capitalization treats \"The\" and \"the\" differently, words like \"the\" and \"it\" dominate counts.\n",
    "\n",
    "Luckily, scikit-learn's CountVectorizer allows for simple preprocessing like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3868f067-62e5-4227-9e81-76485ec7cfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x76 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 76 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit-learn's countvectorizer\n",
    "count = CountVectorizer()\n",
    "neg_vec = count.fit_transform([neg_review])\n",
    "neg_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b990345-6215-4e55-845e-53ad8d5c5e80",
   "metadata": {},
   "source": [
    "`CountVectorizer` outputs a sparse matrix by default.  We can convert that to a normal numpy array and stitch it together with the vocabulary from the `fit()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5628123c-2f0a-48b5-afa3-faf6284f60f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accents': 1, 'actors': 1, 'alan': 1, 'and': 3, 'as': 2, 'been': 1, 'but': 1, 'by': 2, 'cluttered': 1, 'could': 1, 'detective': 1, 'emma': 1, 'entertain': 1, 'entertaining': 1, 'fact': 1, 'film': 1, 'flick': 1, 'for': 3, 'gets': 1, 'give': 1, 'good': 1, 'hal': 1, 'have': 1, 'holbrook': 2, 'if': 1, 'impression': 1, 'in': 2, 'is': 2, 'it': 5, 'kidnappers': 1, 'mannage': 1, 'matter': 1, 'more': 1, 'mostly': 1, 'movie': 3, 'muddles': 1, 'new': 1, 'no': 1, 'not': 1, 'nothing': 1, 'off': 1, 'one': 1, 'orleans': 1, 'performances': 2, 'plot': 1, 'potential': 1, 'pulled': 1, 'rather': 1, 'really': 1, 'rickman': 3, 'scene': 1, 'scenes': 1, 'seeing': 1, 'seems': 1, 'shows': 1, 'southern': 1, 'subplot': 1, 'than': 1, 'that': 2, 'the': 7, 'their': 1, 'these': 1, 'things': 1, 'this': 1, 'thompson': 2, 'three': 1, 'to': 1, 'uninteresting': 2, 'us': 1, 'view': 1, 'was': 1, 'watching': 1, 'well': 1, 'what': 1, 'with': 2, 'worth': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    dict(zip(count.get_feature_names_out(), \n",
    "             neg_vec.toarray().flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c23b3-8d69-4a1b-b2e8-726f88eeb977",
   "metadata": {},
   "source": [
    "We can see the defaults have already done some amount of cleaning for us.\n",
    "\n",
    "#### Deterministic Approach with word counts\n",
    "\n",
    "Let's try a deterministic approach, using word counts and a list of \"positive\" vs \"negative\" words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "251c4e13-03bf-4110-b15a-c128c12c7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = [\"good\", \"great\", \"like\", \"loved\"]\n",
    "neg_words = [\"bad\", \"awful\", \"dislike\", \"hated\"]\n",
    "\n",
    "# we're going to use this train/test split throughout\n",
    "# we'll also use this seed for consistency\n",
    "# NOTE: Usually you'll want to do a separate validation set when choosing models/featuresets!\n",
    "seed = 37\n",
    "np.random.seed(seed)\n",
    "pct_train = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_df['text'],\n",
    "    review_df['label'], train_size=pct_train)\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "train_vecs = cv.fit_transform(X_train)\n",
    "feats = cv.get_feature_names_out()\n",
    "pos_idxs = np.where(np.isin(feats, pos_words))[0]\n",
    "neg_idxs = np.where(np.isin(feats, neg_words))[0]\n",
    "train_det_score = train_vecs[:, pos_idxs].sum(1) - train_vecs[:, neg_idxs].sum(1)\n",
    "# easier for group-level score\n",
    "train_det_score = pd.Series(np.array(train_det_score).ravel(), \n",
    "                            index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765c8284-bb84-46e1-982e-928e140eeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our threshold - the average score for negative, that or below = negative\n",
    "neg_thresh = train_det_score.groupby(review_df['label'].loc[X_train.index]).mean()[False]\n",
    "test_vecs = cv.transform(X_test)\n",
    "test_det_score = test_vecs[:, pos_idxs].sum(1) - test_vecs[:, neg_idxs].sum(1)\n",
    "det_pred = test_det_score>neg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ea3fdf-6cb4-4602-a384-dd05460ac21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.44      0.51      7522\n",
      "        True       0.56      0.71      0.63      7478\n",
      "\n",
      "    accuracy                           0.58     15000\n",
      "   macro avg       0.58      0.58      0.57     15000\n",
      "weighted avg       0.58      0.58      0.57     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(y_pred=det_pred,\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f69c5-72b7-4ae9-8ed8-969818832c07",
   "metadata": {},
   "source": [
    "#### Count Vector + Logistic Regression \n",
    "Here we try a count vector with Logistic Regression.  This alleviates the need for chosing an arbitrary set of terms and arbitrary threshold as above.\n",
    "\n",
    "Here I use scikit-learn's [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).  I won't try and explain how these work, the docs do a better job.  Suffice to say they're useful for ensuring features and models get built in a consistent way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25a9d696-97ba-415d-84d2-503844edf3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english', min_df=0.01)\n",
    "\n",
    "count_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", count),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "952acf7e-5a15-4bb8-88d1-258a634e5cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8654666666666667"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "count_pipeline.fit(X_train, y_train)\n",
    "count_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f58d9f7f-53b2-4cbb-92e6-2d5bac6dcf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.86      0.87      7522\n",
      "        True       0.86      0.87      0.87      7478\n",
      "\n",
      "    accuracy                           0.87     15000\n",
      "   macro avg       0.87      0.87      0.87     15000\n",
      "weighted avg       0.87      0.87      0.87     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(y_pred=count_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30256a1-982a-4aee-877c-7a7045580aa2",
   "metadata": {},
   "source": [
    "This is actually really good! 88% of the time we're predicting the right class with this model.  But can we do...better?\n",
    "\n",
    "### TF-IDF <a class=\"anchor\" id=\"tfidf\"></a>\n",
    "One thing we notice with count vectors is that all words are being counted the same.  We might want to use a weighting scheme to ensure that words that are more informative about the content are flagged as more important.  One weighting scheme is Term Frequency - Inverse Document Frequency (TF-IDF).\n",
    "\n",
    "Take as an example some kind of simplistic movie reviews.  We can already tell which words are most relevant to the specific content of each review (i.e. \"good\", \"bad\", \"great\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "385e0955-d159-4d27-8508-c1a5645a6dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>movie</th>\n",
       "      <th>the</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad  good  great  movie  the  was\n",
       "0    0     1      0      1    1    1\n",
       "1    1     0      0      1    1    1\n",
       "2    0     0      1      1    1    1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ['The movie was good',\n",
    "        'The movie was bad',\n",
    "        'The movie was great']\n",
    "\n",
    "cv = CountVectorizer()\n",
    "vecs = cv.fit_transform(docs).toarray()\n",
    "# we'll use pandas DF for easier display\n",
    "pd.DataFrame(vecs, columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d93d3-aa56-4599-bd57-bd4e12232445",
   "metadata": {},
   "source": [
    "You'll notice that `vecs` contains the term frequencies.  If we use sklearn's `TfidfVectorizer`, it will calculate those term counts and then multiply them by the Inverse Document Frequency (IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30f3611e-8860-411c-b297-e9d2eedca714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>movie</th>\n",
       "      <th>the</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69903</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.69903</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69903</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bad     good    great     movie       the       was\n",
       "0  0.00000  0.69903  0.00000  0.412859  0.412859  0.412859\n",
       "1  0.69903  0.00000  0.00000  0.412859  0.412859  0.412859\n",
       "2  0.00000  0.00000  0.69903  0.412859  0.412859  0.412859"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "# we'll use pandas DF for easier display\n",
    "tfidf_vecs = tfidf.fit_transform(docs).toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_vecs, columns=tfidf.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464164b-5882-48d7-8bb9-f48008ca8d92",
   "metadata": {},
   "source": [
    "You can see that the discriminative words have higher weight than the non-discriminative words.  \n",
    "\n",
    "It's worth noting here - in terms of \"separability\", having 0 vs 1 (count of \"good\" vs count of \"bad\") might actually be better.  But these are highly curated examples - you can imagine cases where good and bad descriptive terms are mixed in a review, you want to capture the words that describe better the \"aboutness\" of the review.  (Think: \"This movie was not bad, it was good!\")\n",
    "\n",
    "Now let's fit our regression as above with TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28f28bdf-371d-4dd7-a25b-63376f3f76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use binary here to handle longer reviews\n",
    "tfidf = TfidfVectorizer(stop_words='english', min_df=0.01)\n",
    "\n",
    "tfidf_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", tfidf),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c7f2b41-18ed-4fab-adee-d5b7bd44c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8712666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.86      0.87      7522\n",
      "        True       0.86      0.88      0.87      7478\n",
      "\n",
      "    accuracy                           0.87     15000\n",
      "   macro avg       0.87      0.87      0.87     15000\n",
      "weighted avg       0.87      0.87      0.87     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "tfidf_pipeline.fit(X_train, y_train)\n",
    "print(f'accuracy: {tfidf_pipeline.score(X_test, y_test)}')\n",
    "print(\n",
    "    classification_report(y_pred=tfidf_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939615a7-eeed-4987-a2a7-bff36a9add4f",
   "metadata": {},
   "source": [
    "The performance has not changed here, but depending on how you tune these approaches, you might see some differences.\n",
    "\n",
    "It's also interesting to see how the different approaches weight different parts of the vocabulary.  In the section below, I look at some of the words whose coefficients in the model have particularly high magnitude (i.e. they're impactful on the decision made by the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10b5b18b-9e54-4ba9-afd3-9a63318aa93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>awful</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>bad</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>boring</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>dull</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>1534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>great</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>1495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>laughable</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>mediocre</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>poor</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>poorly</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>redeeming</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>subtle</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>1541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>terrible</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>waste</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word   tfidf   count\n",
       "111            awful     3.0     4.0\n",
       "114              bad     4.0    70.0\n",
       "155           boring     5.0    22.0\n",
       "367   disappointment     9.0     2.0\n",
       "394             dull     7.0     9.0\n",
       "444        excellent  1540.0  1534.0\n",
       "590            great  1541.0  1495.0\n",
       "761        laughable    24.0     7.0\n",
       "861         mediocre    18.0     6.0\n",
       "1038            poor     8.0    30.0\n",
       "1039          poorly    11.0     8.0\n",
       "1112       redeeming    37.0     5.0\n",
       "1312          subtle  1526.0  1541.0\n",
       "1358        terrible     6.0    16.0\n",
       "1476           waste     2.0     1.0\n",
       "1520           worst     1.0     3.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the coefficients on the LR for each model\n",
    "word_feats = tfidf_pipeline['preprocessor'].get_feature_names_out()\n",
    "# get the largest by magnitude, stitch together to compare\n",
    "top = 10\n",
    "top_tfidf = np.argsort(np.abs(tfidf_pipeline['model'].coef_.flatten()))[-top:]\n",
    "top_count = np.argsort(np.abs(count_pipeline['model'].coef_.flatten()))[-top:]\n",
    "coef_df = pd.DataFrame([\n",
    "    word_feats,\n",
    "    tfidf_pipeline['model'].coef_.ravel(),\n",
    "    count_pipeline['model'].coef_.ravel()],\n",
    "    index=['word', 'tfidf', 'count']).T\n",
    "# normalize result for compare\n",
    "coef_df['tfidf'] = coef_df['tfidf'].rank()\n",
    "coef_df['count'] = coef_df['count'].rank()\n",
    "coef_df.loc[np.unique(np.concatenate([top_tfidf, top_count]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f787f-a6de-4e17-af2b-d7244e21a4cd",
   "metadata": {},
   "source": [
    "Some interesting words would be \"bad\" and \"boring\", which have strong negative associations in the tfidf model, but weaker negative associations in the count model.\n",
    "\n",
    "We can look at where these two models disagree and draw some conclusions about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a3e0d90b-ec5f-46ff-a3da-6684ad26778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most interesting are where there's the largest disagreement\n",
    "tfidf_pred = tfidf_pipeline.predict_proba(X_test)[:, 1]\n",
    "count_pred = count_pipeline.predict_proba(X_test)[:, 1]\n",
    "#top_disagree_idx = np.argsort(np.abs(tfidf_pred - count_pred))[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5eb0ac6f-fa5b-4212-b16b-ea2c2eba4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble in df\n",
    "compare_df = pd.DataFrame([tfidf_pred, count_pred, y_test, X_test],\n",
    "            index=['tfidf_pred', 'count_pred', 'label', 'text']).T\n",
    "# shorten a bit for display\n",
    "compare_df['text'] = compare_df['text'].apply(lambda x: x[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b91b04da-8631-4ce1-ae8c-3a6796572fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df['tfidf_right'] = ((compare_df['tfidf_pred']>=0.5)&(compare_df['label']))|\\\n",
    "    ((compare_df['tfidf_pred']<0.5)&(~compare_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7adecafb-b87b-4382-a781-c90d9d0c5e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_pred: True\n",
      "count_pred: False\n",
      "label: True\n",
      "text: As the '70's drew to a close, rumours began to fly in the entertainment industry about the possible return of Sean Connery to the role he had made famous back in 1962 - James Bond.Cubby Broccoli was asked on location in Brazil during the making of 'Moonraker' by the B.B.C.'s Barry Norman how he viewed the prospect. Understandably, the producer was reluctant to commit himself to an opinion.When 'Moonraker' opened, Bond fans were outraged by what they perceived to be a cheapening of the character, and the jumping onto the 'Star Wars' bandwagon much as 'Live & Let Die' had done with the blaxploitation craze a few years earlier. Many publicly vocalised their hope that Connery would return, if only to show Eon how a real Bond movie should look.Years of legal battles followed. The original script, entitled 'James Bond Of The Secret Service' ( later retitled 'Warhead' ) was written by Kevin McClory, Len Deighton, and Connery, was never filmed, and remains one of the great unmade movie blockbusters.A new script, closer to the 'Thunderball' storyline, was commissioned. It was written by Lorenzo Semple Junior, best known as the man who put the camp into 'Batman'. He had also written 'The Parallax View', one of the decade's finest conspiracy thrillers. Feeling the script needed a British touch, Connery brought in Dick Clement and Ian La Frenais, writers of hit British sitcoms 'The Likely Lads' and 'Porridge'. The witty title was suggested by Connery's wife Micheline. 'Never Say Never Again' opened just before Christmas 1983 to a shower of critical praise; normally sensible critics were so ecstatic at Connery's return they ignored all other aspects of the film. Many used it to viciously attack the Roger Moore series, particularly that year's 'Octopussy'. In truth, 'Octopussy' is superior in every respect. 'Never' lacks the excitement and spectacle one associates with Bond, at times it looks like a made-for-T.V. movie. The story had been done before and better in 1965's 'Thunder\n",
      "tfidf_pred: False\n",
      "count_pred: False\n",
      "label: False\n",
      "text: The brief existence of The Sex Pistols and the making of this film after the controversial, groundbreaking English punk band's break-up both happened before I was born. However, I started listening to their only album, \"Never Mind the B*&%@#&s, Here's the Sex Pistols\", in 2003, when I was a teenager, and quickly became a big fan. I didn't see \"The Great Rock 'n' Roll Swindle\" until 2006, but saw it a couple times that year, and thought it was pretty good (certainly not great, but pretty good), even if I could only remember bits of it, and didn't see how it all connected. Seeing it a third time, nearly three years after the second, I didn't care much for it at all. I'm not even sure what I found so good about most of it in the first place (can't remember now).This film is a mockumentary, in which Sex Pistols manager Malcolm McLaren tells his side of the story of the band and its members; guitarist Steve Jones, credited here as \"The Crook\"; drummer Paul Cook, credited as \"The Tea-Maker\"; bassist Sid Vicious, credited as \"The Gimmick\"; and John Lydon (a.k.a. Johnny Rotten) credited as \"The Collaborator.\" McLaren claims that he created the band (and even the genre of punk rock) as a scam to make money. He tells much of the story to Helen Wellington-Lloyd (a.k.a. Helen of Troy), in various places where they go together. It's basically a hodgepodge of McLaren talking, Pistols songs, live footage of the band, fictional scenes (often silly, strange ones), several cartoon sequences, etc., all put together in one film, to tell the Pistols manager's side of the story in a bizarre way!It has been well proved that McLaren is a liar, I know many have already pointed this out, including band members themselves. He was NOT the driving force of the band, he didn't create them (nor did he invent punk rock, and The Sex Pistols weren't even the first punk band, though they were unique). The band members were the ones who made the band what it was. \"The Filth and the Fury\", a much more \n",
      "tfidf_pred: False\n",
      "count_pred: True\n",
      "label: False\n",
      "text: Ugh. Pretty awful.Linnea Quigley gets top billing, but her character doesn't have a big part. Who is her character supposed to be anyway, the little boy's aunt? Another user commented on her getting nude in a shower scene. While there was a shower scene in the movie, it was a head and shoulders shot. Perhaps there are some alternate versions of this movie.Quigley does have a bigger part than John Carradine, Cameron Mitchell, and Brinke Stevens, though. Carradine shows up briefly in a monkish robe reciting vague dialog. No other characters are in the scene with him, though he's sort of composited in, or else there are over-the-shoulder shots unquestionably belonging to someone else. There's also a really bad photo of him in a cameo locket (it looks like a bad photocopy), and a decent picture of him in a family bible. He conjured up Jack-O originally, or something like that.Cameron Mitchell briefly shows up on a TV as a TV horror host. Brinke Stevens is in the movie he's showing \"The Coven,\" in which she runs around a cemetery in a robe. Evidently there's more of the Brinke footage as a bonus feature on the Retromedia DVD double feature Mark of the Witch/The Brides Wore Blood.Jack-O: what's it about? Darn if I know. A little boy is told a story about a pumpkin-headed demon killer, and he and some other kids are scared by a woman they think is a witch for some reason. She follows him home and offers to help his family with their haunted garage for Halloween (put your hand through a hole and feel eyeballs that are actually grapes, etc.). The pumpkin-headed killer shows up several times to hold onto branches while he watches people, or hold his scythe in front of the camera and pose with it for a while. Sometimes he manages to do more than just stand around holding things, and actually kills people.There are also some flashbacks to a western or prairie family, with the little boy playing the little boy in that family too: ancestors of his, I think. I think they figure in\n"
     ]
    }
   ],
   "source": [
    "# simple way to look at some of these differences\n",
    "for i in compare_df[compare_df.tfidf_right].reindex(top_disagree_idx).head(n=3).itertuples():\n",
    "    print(f'tfidf_pred: {i.tfidf_pred>=0.5}')\n",
    "    print(f'count_pred: {i.count_pred>=0.5}')\n",
    "    print(f'label: {i.label}')\n",
    "    print(f'text: {i.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482b4e9-8a10-461a-93bb-cc1806ea8879",
   "metadata": {},
   "source": [
    "It's difficult to see piecemeal, but it does appear that certain words we associate with negative reviews (e.g. \"awful\") have a stronger influence on prediction in the TF-IDF model.\n",
    "\n",
    "### Topic Models <a class=\"anchor\" id=\"topic\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c5675d7-407d-4127-9858-42c0faaa7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_components(model, word_features, top_display=5):\n",
    "    # utility for displaying respresentative words per component for topic models\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        top_words_idx = topic.argsort()[::-1][:top_display]\n",
    "        top_words = [word_features[i] for i in top_words_idx]\n",
    "        print(\" \".join(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b68b7854-4689-4688-b8b2-bf6aca0de643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the number of components (topics)\n",
    "n_components = 10\n",
    "# adding a few tweaks, just based on experimentation\n",
    "nmf = NMF(n_components=n_components,\n",
    "          init='nndsvda',\n",
    "         max_iter=500)\n",
    "# NMF typically uses tfidf, not word counts\n",
    "# fit tfidf vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vecs = tfidf.fit_transform(review_df['text'])\n",
    "nmf_vecs = nmf.fit_transform(tfidf_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b799b42-2e02-4d29-a2d1-cae86544135d",
   "metadata": {},
   "source": [
    "Both NMF provides a components matrix which corresponds to the loading of each word on each topic.  Higher values means the word is more relevant to that topic.  With the function below, we can display some of the \"representative\" words from each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa3bcf3b-c3e9-4df8-b21c-e564c85addca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "life man story character young\n",
      "Topic 1:\n",
      "movie movies seen watch saw\n",
      "Topic 2:\n",
      "bad acting worst terrible good\n",
      "Topic 3:\n",
      "film films seen director saw\n",
      "Topic 4:\n",
      "just like don really people\n",
      "Topic 5:\n",
      "great good story really best\n",
      "Topic 6:\n",
      "series episode tv episodes season\n",
      "Topic 7:\n",
      "horror gore budget effects scary\n",
      "Topic 8:\n",
      "book read novel story version\n",
      "Topic 9:\n",
      "funny comedy jokes laugh humor\n"
     ]
    }
   ],
   "source": [
    "display_components(nmf, tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29842060-d538-4d93-b643-3d8aaf174518",
   "metadata": {},
   "source": [
    "One neat thing here is we can see which reviews load highly, for example, on this \"horror\" topic (topic 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "573c0925-49b6-4baa-a666-d0b5c21ee2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"The film 'Nightbreed' is one of the best horror films I have ever seen. Overall, I'm not a big fan of horror films, but there is something about this film that is more atmospheric and different from any other horror film I have ever seen. Many horror films i've seen i've enjoyed watching, however, as they are based on horror, I know that the stories are unreal, as they are fictional, therefore I can't take them all seriously. Nightbeed, on the other hand, is a unique horror Genre as it has a feel of realism that i've seen in very few other horror films.This films story on how a man gets murdered and ends up living with the undead in an underground cemetery shelter with undead monsters is the kind of story a person would get from a dreaming Nightmare as its a very unique and original storyline. Most horror films i've seen are all quite fake, but because Nightbreed was so incredibly sophisticated and geniously directed with superb acting, especially by Craig sheffer (Aaron Boone) amazing special effects, great lighting and fantastic dialogue, I found this film to have a sense of depth and maturity with no silly fake horror parody, whatsoever, that many other horror films have. Nightbreed, as well as being horror has elements of thriller, romance and action all rapped in one. If you haven't seen this film, I recommend you watch it, as I rate it a 10/10.\",\n",
       "       \"This is one of the worst horror movies I have ever seen... Unfortunately, I am a horror movie buff and will rent any horror movie unless it's not made for t.v. When looking at the box it says it is rated R for gore and some language... Where was the gore? Was their one good death scene where you actually saw gore? I could have overlooked that if there had been some brief nudity or some good dialogue. There wasn't even one remotely witty or amusing line in this lame movie. Sometimes horror movies are awesome because they are so stupid, but this was just sad.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.iloc[np.argsort(nmf_vecs[:, 7])[-2:]]['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b26740-a871-4c73-a42a-18a9835f5149",
   "metadata": {},
   "source": [
    "Will you look at that - we might have a nice way of \"categorizing\" here.  Let's see how this does with sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f963e47c-6508-45c7-8ff7-2c3742fee335",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', min_df=0.01)\n",
    "nmf = NMF(n_components=n_components,\n",
    "          init='nndsvda',\n",
    "          max_iter=500)\n",
    "clf_nmf_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", tfidf),\n",
    "           (\"topic\", nmf),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a02f3288-f8b7-4bd4-ae62-0bac6cb4bdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7575333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.72      0.75      7522\n",
      "        True       0.74      0.79      0.77      7478\n",
      "\n",
      "    accuracy                           0.76     15000\n",
      "   macro avg       0.76      0.76      0.76     15000\n",
      "weighted avg       0.76      0.76      0.76     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "clf_nmf_pipeline.fit(X_train, y_train)\n",
    "print(f'accuracy: {clf_nmf_pipeline.score(X_test, y_test)}')\n",
    "print(\n",
    "    classification_report(y_pred=clf_nmf_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c03126-fd7a-48f3-ad36-ddd074fc4836",
   "metadata": {},
   "source": [
    "It's not great, but we have much fewer features.  With some tuning, we might be able to get compareable performance with a much smaller feature vector.\n",
    "\n",
    "We may also want to combine these topic vectors with a smaller set of word counts.  Again, this requires some tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe9983bb-8324-487b-aadd-d7da3c6c5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_small = TfidfVectorizer(min_df=0.05, stop_words='english')\n",
    "nmf_pipeline = Pipeline(\n",
    "    steps=[(\"tfdf\", tfidf), \n",
    "           (\"nmf\", nmf)]\n",
    ")\n",
    "clf_union_pipeline = Pipeline(\n",
    "    steps=[('feats',\n",
    "            FeatureUnion(\n",
    "                [(\"tfdf\", tfidf_small), \n",
    "                 (\"nmf\", nmf_pipeline)])),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f28ba72-8aff-4d6c-bfa4-da19a7546a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8064666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.79      0.80      7522\n",
      "        True       0.79      0.83      0.81      7478\n",
      "\n",
      "    accuracy                           0.81     15000\n",
      "   macro avg       0.81      0.81      0.81     15000\n",
      "weighted avg       0.81      0.81      0.81     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "clf_union_pipeline.fit(X_train, y_train)\n",
    "print(f'accuracy: {clf_union_pipeline.score(X_test, y_test)}')\n",
    "print(\n",
    "    classification_report(y_pred=clf_union_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3570f38b-f758-458f-b1ef-b7413ef5e9c4",
   "metadata": {},
   "source": [
    "### Word vectors <a class=\"anchor\" id=\"vectors\"></a>\n",
    "Our next approach is to include context in the word-level representations.  We'll be bringing SpaCy into the mix here, particularly their \"medium\" English web model, which uses GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7bb1334-e39e-4ee3-abd0-8c91acbbe406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33430bf0-6c80-4eae-a807-9a50190659d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run this once\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2abdfd44-0837-43a5-8a84-4d27bb70fe9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22305/116831463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_md\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/spacy/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0menable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/spacy/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b746a-3b95-4519-adfb-b48b111964fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GloveVectorizer(BaseEstimator, TransformerMixin):\n",
    "    # this is a custom document transformer for use in the scikit-learn pipeline\n",
    "    def __init__(self, vectorizer):\n",
    "        self.vectorizer = vectorizer\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # extracts GloVe vector for all words in vectorizer vocabulary (WxV)\n",
    "        self.vectorizer.fit(X)\n",
    "        vocab = self.vectorizer.vocabulary_\n",
    "        self.vocab_glove = np.zeros(shape=(len(vocab), 300))\n",
    "        for token, idx in vocab.items():\n",
    "            self.vocab_glove[idx] = nlp(token).vector\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # create the average GloVe vector for all words in document (D)\n",
    "        # use vectorizer to create DxW vector\n",
    "        X_transformed = self.vectorizer.transform(X).toarray()\n",
    "        # sum of words in D\n",
    "        sum_words = (X_transformed.sum(1)).reshape(-1, 1)\n",
    "        # create DxV vectors\n",
    "        glove_vecs = (X_transformed.dot(self.vocab_glove))/sum_words\n",
    "        return glove_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c76ee-03de-4eb1-a970-a78a45eea54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use binary here to handle longer reviews\n",
    "count = CountVectorizer(stop_words='english', min_df=0.01, binary=False)\n",
    "glove = GloveVectorizer(count)\n",
    "\n",
    "glove_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", glove),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b10c82b-b418-4f60-9f65-e0208bd3097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "glove_pipeline.fit(X_train, y_train)\n",
    "glove_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503d51d-d428-4bff-91df-264379d324fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(y_pred=glove_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93659c0c-ac2c-468f-8098-7b8e227f08c6",
   "metadata": {},
   "source": [
    "In part 2 of the tutorial, we'll be digging into more complex models and breaking out of the \"bagging\" paradigm.  I've separated that portion, as it will likely require use of a GPU to be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe82bfb-2020-4b58-b70e-7eff6cdec0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
