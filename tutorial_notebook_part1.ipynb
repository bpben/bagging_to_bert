{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c2486-cf28-4e32-9b85-3caf4296a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb78f4-b61c-4e56-a1e2-153fb0482523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cfc03-000a-4381-a353-2778f97b2a36",
   "metadata": {},
   "source": [
    "## Bagging to BERT: A tour of applied NLP\n",
    "### Part 1: Four flavors of bagging\n",
    "### Table of Contents\n",
    "* [Data processing](#data)\n",
    "* [Word Counts](#word)\n",
    "* [TF-IDF](#tfidf)\n",
    "* [Topic models](#topic)\n",
    "* [Word vectors](#vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7e591-7d7b-4d92-8f61-d5bb03af5dd7",
   "metadata": {},
   "source": [
    "### Data processing <a class=\"anchor\" id=\"data\"></a>\n",
    "\n",
    "Up first is some preprocessing.  You'll either need to download the [imdb review data](https://ai.stanford.edu/~amaas/data/sentiment/) and save it to this directory OR download the [processed data](https://drive.google.com/file/d/1oN_fO91IBkDHD_u6WXiUCvhhyNexQDJq/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c4ac0-5a90-49ef-b03b-378932d13c9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # processing the original data into DataFrame\n",
    "# # here for reference, don't need to run this if you're using reviews.pkl.gz\n",
    "# source_path = Path('./aclImdb/')\n",
    "# #neg_files = source_path.glob('./*/neg/*.txt')\n",
    "# #pos_files = source_path.glob('./*/pos/*.txt')\n",
    "# all_files = []\n",
    "# for f in source_path.glob('./*/*/*.txt'):\n",
    "#     filename = f.as_posix()\n",
    "#     if 'unsup' not in filename:\n",
    "#         # split up into useful components\n",
    "#         _, split, sent, idx = filename.split('/')\n",
    "#         idx = int(idx.split('_')[0])\n",
    "#         all_files.append([idx, split, sent, f.read_text()])\n",
    "# review_df = pd.DataFrame(all_files)\n",
    "# review_df.columns = ['idx', 'split', 'label', 'text']\n",
    "# # some minor html cruft is in here\n",
    "# review_df['text'] = review_df['text'].str.replace('<br /><br />', '')\n",
    "# review_df = review_df.to_pickle('reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f61ea-8e62-4d21-8f5a-6e3eb1bed2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can skip here if you already have reviews.pkl.gz\n",
    "review_df = pd.read_pickle('reviews.pkl.gz')\n",
    "review_df['label'] = review_df['label'] == 'pos'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db840c0f-9f6d-4058-9913-356eb700dcd0",
   "metadata": {},
   "source": [
    "### Word counts  <a class=\"anchor\" id=\"data\"></a>\n",
    "A very basic way to use a sanitized list of tokens is to do a word count. This unlocks a lot of insights right off and is an important step in exploratory data analysis in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2646a7d-b0f4-406d-bb68-7f5351b425b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a positive and negative review for examples\n",
    "# we'll use Star Wars Episode VI since everyone likes a Star War\n",
    "neg_review = review_df.loc[~review_df.label].iloc[0]['text']\n",
    "pos_review = review_df[review_df.label].iloc[0]['text']\n",
    "print('Negative\\n', neg_review, '\\n')\n",
    "print('Positive\\n', pos_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee60e2b-b1b5-4342-9e7e-8e0e3f17538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base python word count - split on whitespace, use Counter object)\n",
    "print(Counter(neg_review.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c7f82-7e21-42a1-9f70-0c97345ab36a",
   "metadata": {},
   "source": [
    "Already see some things that need to be considered; capitalization treats \"The\" and \"the\" differently, words like \"the\" and \"it\" dominate counts.\n",
    "\n",
    "Luckily, scikit-learn's CountVectorizer allows for simple preprocessing like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868f067-62e5-4227-9e81-76485ec7cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn's countvectorizer\n",
    "count = CountVectorizer()\n",
    "neg_vec = count.fit_transform([neg_review])\n",
    "neg_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b990345-6215-4e55-845e-53ad8d5c5e80",
   "metadata": {},
   "source": [
    "`CountVectorizer` outputs a sparse matrix by default.  We can convert that to a normal numpy array and stitch it together with the vocabulary from the `fit()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628123c-2f0a-48b5-afa3-faf6284f60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    dict(zip(count.get_feature_names_out(), \n",
    "             neg_vec.toarray().flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c23b3-8d69-4a1b-b2e8-726f88eeb977",
   "metadata": {},
   "source": [
    "We can see the defaults have already done some amount of cleaning for us.\n",
    "\n",
    "#### Deterministic Approach with word counts\n",
    "\n",
    "Let's try a deterministic approach, using word counts and a list of \"positive\" vs \"negative\" words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c4e13-03bf-4110-b15a-c128c12c7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = [\"good\", \"great\", \"like\", \"loved\"]\n",
    "neg_words = [\"bad\", \"awful\", \"dislike\", \"hated\"]\n",
    "\n",
    "# we're going to use this train/test split throughout\n",
    "# we'll also use this seed for consistency\n",
    "# NOTE: Usually you'll want to do a separate validation set when choosing models/featuresets!\n",
    "seed = 37\n",
    "np.random.seed(seed)\n",
    "pct_train = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_df['text'],\n",
    "    review_df['label'], train_size=pct_train)\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "train_vecs = cv.fit_transform(X_train)\n",
    "feats = cv.get_feature_names_out()\n",
    "pos_idxs = np.where(np.isin(feats, pos_words))[0]\n",
    "neg_idxs = np.where(np.isin(feats, neg_words))[0]\n",
    "train_det_score = train_vecs[:, pos_idxs].sum(1) - train_vecs[:, neg_idxs].sum(1)\n",
    "# easier for group-level score\n",
    "train_det_score = pd.Series(np.array(train_det_score).ravel(), \n",
    "                            index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c8284-bb84-46e1-982e-928e140eeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our threshold - the average score for negative, that or below = negative\n",
    "neg_thresh = train_det_score.groupby(review_df['label'].loc[X_train.index]).mean()[False]\n",
    "test_vecs = cv.transform(X_test)\n",
    "test_det_score = test_vecs[:, pos_idxs].sum(1) - test_vecs[:, neg_idxs].sum(1)\n",
    "det_pred = test_det_score>neg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea3fdf-6cb4-4602-a384-dd05460ac21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(y_pred=det_pred,\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f69c5-72b7-4ae9-8ed8-969818832c07",
   "metadata": {},
   "source": [
    "#### Count Vector + Logistic Regression \n",
    "Here we try a count vector with Logistic Regression.  This alleviates the need for chosing an arbitrary set of terms and arbitrary threshold as above.\n",
    "\n",
    "Here I use scikit-learn's [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) functionality.  I won't try and explain that here, the docs do a much better job than I can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a9d696-97ba-415d-84d2-503844edf3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english')\n",
    "\n",
    "count_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", count),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952acf7e-5a15-4bb8-88d1-258a634e5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "count_pipeline.fit(X_train, y_train)\n",
    "count_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d9f7f-53b2-4cbb-92e6-2d5bac6dcf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(y_pred=count_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30256a1-982a-4aee-877c-7a7045580aa2",
   "metadata": {},
   "source": [
    "This is actually really good! 88% of the time we're predicting the right class with this model.  But can we do...better?\n",
    "\n",
    "### TF-IDF <a class=\"anchor\" id=\"tfidf\"></a>\n",
    "One thing we notice with count vectors is that all words are being counted the same.  We might want to use a weighting scheme to ensure that words that are more informative about the content are flagged as more important.  One weighting scheme is Term Frequency - Inverse Document Frequency (TF-IDF).\n",
    "\n",
    "Take as an example some kind of simplistic movie reviews.  We can already tell which words are most relevant to the specific content of each review (i.e. \"good\", \"bad\", \"great\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e0955-d159-4d27-8508-c1a5645a6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['The movie was good',\n",
    "        'The movie was bad',\n",
    "        'The movie was great']\n",
    "\n",
    "cv = CountVectorizer()\n",
    "vecs = cv.fit_transform(docs).toarray()\n",
    "# we'll use pandas DF for easier display\n",
    "pd.DataFrame(vecs, columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d93d3-aa56-4599-bd57-bd4e12232445",
   "metadata": {},
   "source": [
    "You'll notice that `vecs` contains the term frequencies.  If we use sklearn's `TfidfVectorizer`, it will calculate those term counts and then multiply them by the Inverse Document Frequency (IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3611e-8860-411c-b297-e9d2eedca714",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "# we'll use pandas DF for easier display\n",
    "tfidf_vecs = tfidf.fit_transform(docs).toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_vecs, columns=tfidf.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464164b-5882-48d7-8bb9-f48008ca8d92",
   "metadata": {},
   "source": [
    "You can see that the discriminative words have higher weight than the non-discriminative words.  \n",
    "\n",
    "It's worth noting here - in terms of \"separability\", having 0 v 1 (count of \"good\" vs count of \"bad\") might actually be better.  But these are highly curated examples - you can imagine cases where good and bad descriptive terms are mixed in a review, you want to capture the words that describe better the \"aboutness\" of the review.  (Think: \"This movie was not bad, it was good!\")\n",
    "\n",
    "Now let's fit our regression as above with TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f28bdf-371d-4dd7-a25b-63376f3f76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use binary here to handle longer reviews\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tfidf_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", tfidf),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f2b41-18ed-4fab-adee-d5b7bd44c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "tfidf_pipeline.fit(X_train, y_train)\n",
    "print(f'accuracy: {tfidf_pipeline.score(X_test, y_test)}')\n",
    "print(\n",
    "    classification_report(y_pred=tfidf_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5b18b-9e54-4ba9-afd3-9a63318aa93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the coefficients on the LR for each model\n",
    "word_feats = tfidf_pipeline['preprocessor'].get_feature_names_out()\n",
    "# get the largest by magnitude, stitch together to compare\n",
    "top = 10\n",
    "top_tfidf = np.argsort(np.abs(tfidf_pipeline['model'].coef_.flatten()))[-top:]\n",
    "top_count = np.argsort(np.abs(count_pipeline['model'].coef_.flatten()))[-top:]\n",
    "# top\n",
    "coef_df = pd.DataFrame([\n",
    "    word_feats,\n",
    "    tfidf_pipeline['model'].coef_.flatten(),\n",
    "    count_pipeline['model'].coef_.flatten()],\n",
    "    index=['word', 'tfidf', 'count']).T\n",
    "# normalize result for compare\n",
    "coef_df['tfidf'] = coef_df['tfidf'].rank()\n",
    "coef_df['count'] = coef_df['count'].rank()\n",
    "coef_df.loc[np.unique(np.concatenate([top_tfidf, top_count]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0d90b-ec5f-46ff-a3da-6684ad26778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples where there's disagreement\n",
    "tfidf_pred = tfidf_pipeline.predict_proba(X_test)[:, 1]\n",
    "count_pred = count_pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456f39f-b53c-4293-aadf-a4725db61123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most interesting are where there's the largest disagreement\n",
    "top_disagree_idx = np.argsort(np.abs(tfidf_pred - count_pred))[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f8ac0-64a1-43c4-aeac-ba6488050b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble in df\n",
    "compare_df = pd.DataFrame([tfidf_pred, count_pred, y_test, X_test],\n",
    "            index=['tfidf_pred', 'count_pred', 'label', 'text']).T\n",
    "# would like some shorter mv reviews here\n",
    "compare_df['text'] = compare_df['text'].apply(lambda x: x[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b04da-8631-4ce1-ae8c-3a6796572fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df['tfidf_right'] = ((compare_df['tfidf_pred']>=0.5)&(compare_df['label']=='pos'))|\\\n",
    "    ((compare_df['tfidf_pred']<0.5)&(compare_df['label']=='neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adecafb-b87b-4382-a781-c90d9d0c5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple way to look at some of these differences\n",
    "#compare_df[compare_df.tfidf_right].reindex(top_disagree_idx).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482b4e9-8a10-461a-93bb-cc1806ea8879",
   "metadata": {},
   "source": [
    "It's difficult to see piecemeal, but it does appear that certain words we associate with negative reviews (e.g. \"bad\") have a stronger influence on prediction in the TF-IDF model.\n",
    "\n",
    "### Topic Models <a class=\"anchor\" id=\"topic\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5675d7-407d-4127-9858-42c0faaa7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_components(model, word_features, top_display=5):\n",
    "    # utility for displaying respresentative words per component for topic models\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        top_words_idx = topic.argsort()[::-1][:top_display]\n",
    "        top_words = [word_features[i] for i in top_words_idx]\n",
    "        print(\" \".join(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b7854-4689-4688-b8b2-bf6aca0de643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the number of components (topics)\n",
    "n_components = 10\n",
    "# adding a few tweaks, just based on experimentation\n",
    "nmf = NMF(n_components=n_components,\n",
    "          init='nndsvda',\n",
    "         max_iter=500)\n",
    "# NMF typically uses tfidf, not word counts\n",
    "# fit tfidf vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vecs = tfidf.fit_transform(review_df['text'])\n",
    "nmf_vecs = nmf.fit_transform(tfidf_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b799b42-2e02-4d29-a2d1-cae86544135d",
   "metadata": {},
   "source": [
    "Both NMF provides a components matrix which corresponds to the loading of each word on each topic.  Higher values means the word is more relevant to that topic.  With the function below, we can display some of the \"representative\" words from each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3bcf3b-c3e9-4df8-b21c-e564c85addca",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_components(nmf, tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29842060-d538-4d93-b643-3d8aaf174518",
   "metadata": {},
   "source": [
    "One neat thing here is we can see which reviews load highly, for example, on this \"horror\" topic (topic 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c0925-49b6-4baa-a666-d0b5c21ee2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.iloc[np.argsort(nmf_vecs[:, 7])[-2:]]['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b26740-a871-4c73-a42a-18a9835f5149",
   "metadata": {},
   "source": [
    "Will you look at that - we might have a nice way of \"categorizing\" here.  Let's see how this does with sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963e47c-6508-45c7-8ff7-2c3742fee335",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "nmf = NMF(n_components=n_components,\n",
    "          init='nndsvda',\n",
    "          max_iter=500)\n",
    "clf_nmf_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", tfidf),\n",
    "           (\"topic\", nmf),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f3288-f8b7-4bd4-ae62-0bac6cb4bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "clf_nmf_pipeline.fit(X_train, y_train)\n",
    "print(f'accuracy: {clf_nmf_pipeline.score(X_test, y_test)}')\n",
    "print(\n",
    "    classification_report(y_pred=clf_nmf_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c03126-fd7a-48f3-ad36-ddd074fc4836",
   "metadata": {},
   "source": [
    "It's not great, but we have much fewer features.  With some tuning, we might be able to get compareable performance with a much smaller feature vector.\n",
    "\n",
    "We may also want to combine these topic vectors with a smaller set of word counts.  Again, this requires some tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9983bb-8324-487b-aadd-d7da3c6c5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_small = TfidfVectorizer(min_df=0.05, stop_words='english')\n",
    "\n",
    "clf_union_pipeline = Pipeline(\n",
    "    steps=[('feats',\n",
    "            FeatureUnion(\n",
    "                [(\"tfdf\", tfidf_small), \n",
    "                 (\"nmf\", nmf_pipeline)])),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28ba72-8aff-4d6c-bfa4-da19a7546a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "clf_union_pipeline.fit(X_train, y_train)\n",
    "print(f'accuracy: {clf_union_pipeline.score(X_test, y_test)}')\n",
    "print(\n",
    "    classification_report(y_pred=clf_union_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3570f38b-f758-458f-b1ef-b7413ef5e9c4",
   "metadata": {},
   "source": [
    "### Word vectors <a class=\"anchor\" id=\"vectors\"></a>\n",
    "Our next approach is to include context in the word-level representations.  We'll be bringing SpaCy into the mix here, particularly their \"medium\" English web model, which uses GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb1334-e39e-4ee3-abd0-8c91acbbe406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33430bf0-6c80-4eae-a807-9a50190659d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run this once\n",
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abdfd44-0837-43a5-8a84-4d27bb70fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b746a-3b95-4519-adfb-b48b111964fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GloveVectorizer(BaseEstimator, TransformerMixin):\n",
    "    # this is a custom document transformer for use in the scikit-learn pipeline\n",
    "    def __init__(self, vectorizer):\n",
    "        self.vectorizer = vectorizer\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # extracts GloVe vector for all words in vectorizer vocabulary (WxV)\n",
    "        self.vectorizer.fit(X)\n",
    "        vocab = self.vectorizer.vocabulary_\n",
    "        self.vocab_glove = np.zeros(shape=(len(vocab), 300))\n",
    "        for token, idx in vocab.items():\n",
    "            self.vocab_glove[idx] = nlp(token).vector\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # create the average GloVe vector for all words in document (D)\n",
    "        # use vectorizer to create DxW vector\n",
    "        X_transformed = self.vectorizer.transform(X).toarray()\n",
    "        # sum of words in D\n",
    "        sum_words = (X_transformed.sum(1)).reshape(-1, 1)\n",
    "        # create DxV vectors\n",
    "        glove_vecs = (X_transformed.dot(self.vocab_glove))/sum_words\n",
    "        return glove_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c76ee-03de-4eb1-a970-a78a45eea54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use binary here to handle longer reviews\n",
    "count = CountVectorizer(stop_words='english', min_df=0.01, binary=False)\n",
    "glove = GloveVectorizer(count)\n",
    "\n",
    "glove_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", glove),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b10c82b-b418-4f60-9f65-e0208bd3097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "glove_pipeline.fit(X_train, y_train)\n",
    "glove_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503d51d-d428-4bff-91df-264379d324fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(y_pred=glove_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93659c0c-ac2c-468f-8098-7b8e227f08c6",
   "metadata": {},
   "source": [
    "In part 2 of the tutorial, we'll be digging into more complex models and breaking out of the \"bagging\" paradigm.  I've separated that portion, as it will likely require use of a GPU to be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe82bfb-2020-4b58-b70e-7eff6cdec0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy3",
   "language": "python",
   "name": "spacy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
