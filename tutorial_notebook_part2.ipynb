{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b755db-c27b-486b-bf26-247067066fef",
   "metadata": {
    "id": "a3b755db-c27b-486b-bf26-247067066fef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b.batorsky/.conda/envs/spacy/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "from spacy.cli.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a30af8d-ce1b-4e43-b07a-a42cc4bc6642",
   "metadata": {
    "id": "4a30af8d-ce1b-4e43-b07a-a42cc4bc6642"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052dc370-eb8d-4ea0-a0a2-9d722531ced6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bagging to BERT: A tour of applied NLP\n",
    "### Part 2: Beyond bagging\n",
    "### Table of Contents\n",
    "* [CNN TextCat](#cnn)\n",
    "* [BERT](#bert)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a5a18-11e6-4f8e-a226-6e7eed06cc6d",
   "metadata": {
    "id": "77c7e591-7d7b-4d92-8f61-d5bb03af5dd7"
   },
   "source": [
    "### Data processing <a class=\"anchor\" id=\"data\"></a>\n",
    "\n",
    "Copied from part 1\n",
    "\n",
    "You'll either need to download the [imdb review data](https://ai.stanford.edu/~amaas/data/sentiment/) and save it to this directory OR download the [processed data](https://drive.google.com/file/d/1oN_fO91IBkDHD_u6WXiUCvhhyNexQDJq/view?usp=sharinghttps://drive.google.com/file/d/1oN_fO91IBkDHD_u6WXiUCvhhyNexQDJq/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3c4ac0-5a90-49ef-b03b-378932d13c9a",
   "metadata": {
    "id": "9b3c4ac0-5a90-49ef-b03b-378932d13c9a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # processing the original data into DataFrame\n",
    "# # here for reference, don't need to run this if you're using reviews.pkl.gz\n",
    "# source_path = Path('./aclImdb/')\n",
    "# #neg_files = source_path.glob('./*/neg/*.txt')\n",
    "# #pos_files = source_path.glob('./*/pos/*.txt')\n",
    "# all_files = []\n",
    "# for f in source_path.glob('./*/*/*.txt'):\n",
    "#     filename = f.as_posix()\n",
    "#     if 'unsup' not in filename:\n",
    "#         # split up into useful components\n",
    "#         _, split, sent, idx = filename.split('/')\n",
    "#         idx = int(idx.split('_')[0])\n",
    "#         all_files.append([idx, split, sent, f.read_text()])\n",
    "# review_df = pd.DataFrame(all_files)\n",
    "# review_df.columns = ['idx', 'split', 'label', 'text']\n",
    "# # some minor html cruft is in here\n",
    "# review_df['text'] = review_df['text'].str.replace('<br /><br />', '')\n",
    "# review_df = review_df.to_pickle('reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qWn_t_XRLPpb",
   "metadata": {
    "id": "qWn_t_XRLPpb"
   },
   "outputs": [],
   "source": [
    "# you may need to restart after this in Collab\n",
    "!pip install spacy-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cSe1LvjvLmte",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSe1LvjvLmte",
    "outputId": "5eaa8d28-472f-4eed-eff2-e7a1582dc7af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "em-MR4WcaeeR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "em-MR4WcaeeR",
    "outputId": "a2b0d81e-bbf5-4bbe-a50d-1f6e330a2554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bagging_to_bert'...\n",
      "remote: Enumerating objects: 72, done.\u001b[K\n",
      "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
      "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
      "remote: Total 72 (delta 36), reused 53 (delta 17), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (72/72), 27.39 MiB | 11.39 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b revised_2023 https://github.com/bpben/bagging_to_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "T6wGvK15ajhd",
   "metadata": {
    "id": "T6wGvK15ajhd"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, labels, name):\n",
    "    # preprocessing utility for saving a serialized corpus for spaCy\n",
    "    # initialize spaCy's DocBin format (easier use with spaCy pipeline)\n",
    "    db = DocBin()\n",
    "    output_path = f'{name}.spacy'\n",
    "    data_tuples = zip(text, labels)\n",
    "    # pipe is slightly faster than individually processing each\n",
    "    for doc, label in nlp.pipe(data_tuples, as_tuples=True):\n",
    "        # store the labels in the document's .cat attribute\n",
    "        if label == 'pos':\n",
    "            doc.cats['pos'] = True\n",
    "            doc.cats['neg'] = False\n",
    "        else:\n",
    "            doc.cats['pos'] = False\n",
    "            doc.cats['neg'] = True\n",
    "        db.add(doc)\n",
    "    # save the DocBin\n",
    "    db.to_disk(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "W-QB_EmLbEvv",
   "metadata": {
    "id": "W-QB_EmLbEvv"
   },
   "outputs": [],
   "source": [
    "# spaCy default corpus reader has certain expectations about format\n",
    "#review_df = pd.read_pickle(\n",
    "#    '/content/drive/MyDrive/talks/odsc_2023/reviews.pkl.gz')\n",
    "review_df = pd.read_pickle('reviews.pkl.gz')\n",
    "# copied from part 1: want to use the same train/test split\n",
    "seed = 37\n",
    "np.random.seed(seed)\n",
    "pct_train = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_df['text'],\n",
    "    review_df['label'], train_size=pct_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "w4kXX9W06JaS",
   "metadata": {
    "id": "w4kXX9W06JaS"
   },
   "outputs": [],
   "source": [
    "# running the preprocessing on each split\n",
    "preprocess(X_train, y_train, 'train')\n",
    "preprocess(X_test, y_test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85c795cb-66e0-48d5-a28a-4476ca1cef64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85c795cb-66e0-48d5-a28a-4476ca1cef64",
    "outputId": "1a114268-3cd7-46c7-9929-7e1ba2189c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: cnn_model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.25       33.27    0.33\n",
      "  0     200         50.01       33.43    0.33\n",
      "  0     400         50.05       52.54    0.53\n",
      "  0     600         49.71       33.27    0.33\n",
      "  0     800         50.01       33.47    0.33\n",
      "  0    1000         49.35       33.31    0.33\n",
      "  0    1200         47.20       38.59    0.39\n",
      "  0    1400         46.09       67.90    0.68\n",
      "  0    1600         45.65       67.69    0.68\n",
      "  0    1800         42.11       64.96    0.65\n",
      "  0    2000         41.06       69.31    0.69\n",
      "  0    2200         38.22       72.62    0.73\n",
      "  0    2400         37.78       69.83    0.70\n",
      "  0    2600         38.62       71.15    0.71\n",
      "  0    2800         35.41       73.56    0.74\n",
      "  0    3000         36.38       64.98    0.65\n",
      "  0    3200         44.47       73.78    0.74\n",
      "  0    3400         36.06       74.28    0.74\n",
      "  0    3600         33.86       75.08    0.75\n",
      "  0    3800         34.38       75.08    0.75\n",
      "  0    4000         35.00       70.58    0.71\n",
      "  0    4200         40.15       75.34    0.75\n",
      "  0    4400         32.36       76.74    0.77\n",
      "  0    4600         31.16       77.16    0.77\n",
      "  0    4800         35.58       75.98    0.76\n",
      "  0    5000         31.87       77.77    0.78\n",
      "  0    5200         31.36       75.64    0.76\n",
      "  0    5400         31.05       77.79    0.78\n",
      "  0    5600         34.41       77.93    0.78\n",
      "  0    5800         34.56       76.36    0.76\n",
      "  0    6000         31.80       78.70    0.79\n",
      "  0    6200         37.22       78.38    0.78\n",
      "  0    6400         28.31       79.30    0.79\n",
      "  0    6600         35.40       79.36    0.79\n",
      "  0    6800         32.49       79.71    0.80\n",
      "  0    7000         27.09       78.24    0.78\n",
      "  0    7200         28.68       76.89    0.77\n",
      "  0    7400         30.82       78.17    0.78\n",
      "  0    7600         37.82       79.76    0.80\n",
      "  0    7800         21.09       78.64    0.79\n",
      "  0    8000         31.58       79.58    0.80\n",
      "  0    8200         27.07       79.89    0.80\n",
      "  0    8400         27.27       78.28    0.78\n",
      "  0    8600         22.74       80.73    0.81\n",
      "  0    8800         31.68       79.70    0.80\n",
      "  0    9000         26.57       78.73    0.79\n",
      "  0    9200         27.44       80.27    0.80\n",
      "  0    9400         31.04       79.20    0.79\n",
      "  0    9600         30.72       80.79    0.81\n",
      "  0    9800         24.93       80.61    0.81\n",
      "  0   10000         30.59       80.38    0.80\n",
      "  0   10200         26.19       80.73    0.81\n",
      "  0   10400         31.50       80.63    0.81\n",
      "  0   10600         19.72       78.68    0.79\n",
      "  0   10800         29.67       80.86    0.81\n",
      "  0   11000         29.28       81.22    0.81\n",
      "  0   11200         24.57       80.92    0.81\n",
      "  0   11400         28.23       81.47    0.81\n",
      "  0   11600         23.70       79.29    0.79\n",
      "  0   11800         26.89       81.25    0.81\n",
      "  0   12000         26.47       81.38    0.81\n",
      "  0   12200         28.27       81.58    0.82\n",
      "  0   12400         29.51       81.58    0.82\n",
      "  0   12600         25.40       81.36    0.81\n",
      "  0   12800         27.12       81.53    0.82\n",
      "  0   13000         30.56       81.76    0.82\n",
      "  0   13200         23.78       81.91    0.82\n",
      "  0   13400         31.34       81.09    0.81\n",
      "  0   13600         31.64       81.50    0.82\n",
      "  0   13800         30.81       81.96    0.82\n",
      "  0   14000         33.71       82.01    0.82\n",
      "  0   14200         30.34       80.47    0.80\n",
      "  0   14400         28.75       81.95    0.82\n",
      "  0   14600         29.78       81.27    0.81\n",
      "  0   14800         25.95       82.36    0.82\n",
      "  0   15000         29.00       82.30    0.82\n",
      "  0   15200         32.19       81.27    0.81\n",
      "  0   15400         24.28       81.90    0.82\n",
      "  0   15600         27.26       81.91    0.82\n",
      "  0   15800         25.36       81.59    0.82\n",
      "  0   16000         20.91       82.56    0.83\n",
      "  0   16200         21.94       82.45    0.82\n",
      "  0   16400         25.36       82.26    0.82\n",
      "  0   16600         23.95       81.81    0.82\n",
      "  0   16800         20.85       81.52    0.82\n",
      "  0   17000         25.85       81.36    0.81\n",
      "  0   17200         28.90       82.50    0.82\n",
      "  0   17400         24.06       81.57    0.82\n",
      "  0   17600         28.82       81.54    0.82\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "cnn_model/model-last\n"
     ]
    }
   ],
   "source": [
    "# can override config info with overrides\n",
    "# the tutorial config file doesn't have the paths for train/dev corpora\n",
    "# going to just run this for a few epochs, see how it works\n",
    "train(\"./spacy_materials/config.cfg\",\n",
    "      output_path='cnn_model',\n",
    "      overrides={\"paths.train\": \"train.spacy\", \n",
    "                 \"paths.dev\": \"test.spacy\",\n",
    "                 \"training.max_epochs\": 5},\n",
    "      use_gpu = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qdmGkvsPQoEu",
   "metadata": {
    "id": "qdmGkvsPQoEu"
   },
   "outputs": [],
   "source": [
    "# load the best version of the model\n",
    "m = spacy.load('/content/drive/MyDrive/talks/odsc_2023/trained_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "074342c4-c93c-486a-b1d7-4d57318edb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best version of the model\n",
    "m = spacy.load('./cnn_model/model-best/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "yFmuwUE6-xP9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFmuwUE6-xP9",
    "outputId": "6fcf4123-d20b-4e5e-b9fe-9e3bb4a0443d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': 0.9997627139091492, 'neg': 0.00023723322374280542}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the outputs from running a simple example\n",
    "m('This movie is great').cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cUaNYxfHAECZ",
   "metadata": {
    "id": "cUaNYxfHAECZ"
   },
   "source": [
    "SpaCy has its own evaluation capabilities, but for comparison's sake, let's use the same evaluation approach we did with out other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2a1bba-c867-4166-ad98-6b09705a9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're interested in trying out spacy's own evaluate\n",
    "#from spacy.cli.evaluate import evaluate\n",
    "#evaluate(model='./example_model/model-best/', data_path='test.spacy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Ih7n0wGxABGa",
   "metadata": {
    "id": "Ih7n0wGxABGa"
   },
   "outputs": [],
   "source": [
    "# if you're interested in trying out spacy's own evaluate\n",
    "from spacy.cli.evaluate import evaluate\n",
    "evaluate(model='./cnn_model/model-best/', data_path='test.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "I6HiG41AAeSH",
   "metadata": {
    "id": "I6HiG41AAeSH"
   },
   "outputs": [],
   "source": [
    "# get the predicted category from the model\n",
    "pred = np.array([max(d.cats, key=d.cats.get) for d in m.pipe(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9WIqefqOBF1Y",
   "metadata": {
    "id": "9WIqefqOBF1Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.83      0.82      0.83      7522\n",
      "         pos       0.82      0.83      0.83      7478\n",
      "\n",
      "    accuracy                           0.83     15000\n",
      "   macro avg       0.83      0.83      0.83     15000\n",
      "weighted avg       0.83      0.83      0.83     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {np.where(pred == y_test)[0].shape[0]/y_test.shape[0]}')\n",
    "print(\n",
    "    classification_report(y_pred=pred,\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9536ef-ae86-406f-92f2-8ef3fb07db18",
   "metadata": {
    "id": "1d9536ef-ae86-406f-92f2-8ef3fb07db18"
   },
   "source": [
    "### BERT <a class=\"anchor\" id=\"bert!pip install transformers\"></a>\n",
    "From [HF tutorials](https://huggingface.co/blog/sentiment-analysis-python).  The sentiment analysis pipeline packages together the tokenizer and the BERT model with a classification layer.  The default pipeline uses this [distilBERT model](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d48a465-92d4-44ab-9fb6-8eeefb3971ea",
   "metadata": {
    "id": "5d48a465-92d4-44ab-9fb6-8eeefb3971ea"
   },
   "outputs": [],
   "source": [
    "# this will need to be run if you don't already have this package\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c60eb292-ff25-4f5e-bf00-a7c8672c758f",
   "metadata": {
    "id": "c60eb292-ff25-4f5e-bf00-a7c8672c758f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
      "Downloading: 100%|██████████| 629/629 [00:00<00:00, 394kB/s]\n",
      "Downloading: 100%|██████████| 255M/255M [00:04<00:00, 57.3MB/s] \n",
      "Downloading: 100%|██████████| 48.0/48.0 [00:00<00:00, 14.5kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 4.39MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24b3e58f-5b03-41a2-92f7-69beb3fc0aee",
   "metadata": {
    "id": "24b3e58f-5b03-41a2-92f7-69beb3fc0aee"
   },
   "outputs": [],
   "source": [
    "# some manipulations for speed and to play nice with BERT\n",
    "bert_pred = sentiment_pipeline(X_test.apply(lambda x: x).head(n=50).tolist())\n",
    "bert_pred = ['pos' if p['label']=='POSITIVE' else 'neg' for p in bert_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25afb1f9-1e29-463d-b4f9-50dcdd0c2af8",
   "metadata": {
    "id": "25afb1f9-1e29-463d-b4f9-50dcdd0c2af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.90      0.90      0.90        30\n",
      "         pos       0.85      0.85      0.85        20\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.88      0.88      0.88        50\n",
      "weighted avg       0.88      0.88      0.88        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.where(bert_pred == y_test[:50])\n",
    "print(f'accuracy: {np.where(bert_pred == y_test[:50])[0].shape[0]/50}')\n",
    "print(\n",
    "    classification_report(y_pred=bert_pred,\n",
    "                          y_true=y_test[:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b39f4-73a9-45b9-9992-2246fe5c5aed",
   "metadata": {},
   "source": [
    "This is pretty good! But with some minor modifications, we can use our spacy configuration with a transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff918c-7865-4f84-9e88-5660f3042de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: example_model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ------------  ----------  ------\n",
      "  0     400           0.01         29.13       84.27    0.84\n",
      "  0     600           0.02         21.04       84.58    0.85\n",
      "  0     800           0.04         28.55       83.93    0.84\n",
      "  0    1000           0.05         30.94       84.81    0.85\n",
      "  0    1200           0.06         27.66       88.08    0.88\n",
      "  0    1400           0.06         20.69       82.18    0.82\n",
      "  0    1600           0.09         28.52       86.84    0.87\n",
      "  0    1800           0.09         22.07       84.13    0.84\n",
      "  0    2000           0.09         25.36       82.88    0.83\n",
      "  0    2200           0.14         21.18       86.39    0.86\n",
      "  0    2400           0.16         28.54       85.74    0.86\n",
      "  0    2600           0.12         15.82       79.71    0.80\n",
      "  0    2800           0.18         28.11       85.28    0.85\n",
      "  0    3000           0.14         22.15       87.29    0.87\n",
      "  0    3200           0.18         22.81       87.12    0.87\n",
      "  0    3400           0.19         23.69       86.95    0.87\n",
      "  0    3600           0.23         24.48       88.16    0.88\n",
      "  0    3800           0.14         14.90       87.61    0.88\n",
      "  0    4000           0.28         25.35       88.51    0.89\n",
      "  0    4200           0.22         23.34       86.44    0.86\n",
      "  0    4400           0.14         15.51       85.85    0.86\n",
      "  0    4600           0.23         23.89       87.36    0.87\n",
      "  0    4800           0.29         21.60       87.50    0.88\n",
      "  0    5000           0.34         20.91       86.93    0.87\n",
      "  0    5200           0.31         22.11       87.70    0.88\n",
      "  0    5400           0.24         20.16       86.42    0.86\n",
      "  0    5600           0.28         23.27       79.45    0.79\n",
      "  0    5800           0.31         22.99       87.49    0.87\n",
      "  0    6000           0.30         24.23       86.31    0.86\n",
      "  0    6200           0.25         21.75       87.11    0.87\n",
      "  0    6400           0.20         18.03       87.34    0.87\n",
      "  0    6600           0.22         16.82       88.50    0.88\n",
      "  0    6800           0.26         18.85       84.33    0.84\n",
      "  0    7000           0.34         22.27       88.74    0.89\n",
      "  0    7200           0.22         18.16       77.18    0.77\n",
      "  0    7400           0.48         30.05       88.99    0.89\n",
      "  0    7600           0.33         22.71       85.27    0.85\n",
      "  0    7800           0.18         17.45       88.91    0.89\n",
      "  0    8000           0.20         15.39       88.19    0.88\n",
      "  0    8200           0.29         18.97       84.79    0.85\n",
      "  0    8400           0.33         21.08       89.67    0.90\n",
      "  0    8600           0.23         14.03       85.51    0.86\n",
      "  0    8800           0.45         26.26       89.87    0.90\n",
      "  0    9000           0.20         16.14       88.76    0.89\n",
      "  0    9200           0.24         16.15       88.18    0.88\n",
      "  0    9400           0.29         18.67       88.76    0.89\n",
      "  0    9600           0.20         12.73       88.07    0.88\n",
      "  0    9800           0.19         10.73       86.91    0.87\n",
      "  0   10000           0.31         21.08       87.62    0.88\n",
      "  0   10200           0.32         19.48       86.45    0.86\n",
      "  0   10400           0.29         20.07       82.92    0.83\n",
      "  0   10600           0.43         21.81       82.21    0.82\n",
      "  0   10800           0.24         18.04       89.14    0.89\n",
      "  0   11000           0.34         19.99       88.60    0.89\n",
      "  0   11400           0.34         18.92       89.89    0.90\n",
      "  0   11600           0.15         11.69       85.75    0.86\n",
      "  0   11800           0.34         21.17       88.98    0.89\n",
      "  0   12000           0.25         20.38       89.86    0.90\n",
      "  0   12200           0.37         19.30       89.58    0.90\n",
      "  0   12400           0.30         17.70       89.42    0.89\n",
      "  0   12600           0.29         18.13       89.47    0.89\n"
     ]
    }
   ],
   "source": [
    "# can override config info with overrides\n",
    "# the tutorial config file doesn't have the paths for train/dev corpora\n",
    "# going to just run this for a few epochs, see how it works\n",
    "train(\"./spacy_materials/config_trf.cfg\",\n",
    "      output_path='example_model',\n",
    "      overrides={\"paths.train\": \"train.spacy\", \n",
    "                 \"paths.dev\": \"test.spacy\",\n",
    "                 \"training.max_epochs\": 5},\n",
    "      use_gpu = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8d0388-3777-45f0-ba4c-d25109be26db",
   "metadata": {
    "id": "qdmGkvsPQoEu"
   },
   "outputs": [],
   "source": [
    "# load the best version of the model\n",
    "m = spacy.load('/content/drive/MyDrive/talks/odsc_2023/trained_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe9c9877-133d-4e0e-a17d-400301b79165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best version of the model\n",
    "m = spacy.load('./example_model/model-best/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952309ec-2b71-431d-b5ca-27ef329be660",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFmuwUE6-xP9",
    "outputId": "6fcf4123-d20b-4e5e-b9fe-9e3bb4a0443d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': 0.9998667240142822, 'neg': 0.00013326172484084964}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the outputs from running a simple example\n",
    "m('This movie is great').cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2a97f-f54d-423a-bdca-f349172ec8dd",
   "metadata": {
    "id": "Ih7n0wGxABGa"
   },
   "outputs": [],
   "source": [
    "# if you're interested in trying out spacy's own evaluate\n",
    "from spacy.cli.evaluate import evaluate\n",
    "evaluate(model='./example_model/model-best/', data_path='test.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11844ac7-e9fa-4017-a7fa-97407ccd4666",
   "metadata": {
    "id": "I6HiG41AAeSH"
   },
   "outputs": [],
   "source": [
    "# get the predicted category from the model\n",
    "pred = np.array([max(d.cats, key=d.cats.get) for d in m.pipe(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8b35047-fe33-4f53-a65a-9df64b3838d2",
   "metadata": {
    "id": "9WIqefqOBF1Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.92      0.89      0.90      7522\n",
      "         pos       0.89      0.92      0.90      7478\n",
      "\n",
      "    accuracy                           0.90     15000\n",
      "   macro avg       0.90      0.90      0.90     15000\n",
      "weighted avg       0.90      0.90      0.90     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {np.where(pred == y_test)[0].shape[0]/y_test.shape[0]}')\n",
    "print(\n",
    "    classification_report(y_pred=pred,\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd40acf-9a6f-4c2e-a3ae-53268c69a6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
