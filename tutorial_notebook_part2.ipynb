{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b755db-c27b-486b-bf26-247067066fef",
   "metadata": {
    "id": "a3b755db-c27b-486b-bf26-247067066fef"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a30af8d-ce1b-4e43-b07a-a42cc4bc6642",
   "metadata": {
    "id": "4a30af8d-ce1b-4e43-b07a-a42cc4bc6642"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052dc370-eb8d-4ea0-a0a2-9d722531ced6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bagging to BERT: A tour of applied NLP\n",
    "### Part 2: Beyond bagging\n",
    "### Table of Contents\n",
    "* [LSTM](#lstm)\n",
    "* [BERT](#bert)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a5a18-11e6-4f8e-a226-6e7eed06cc6d",
   "metadata": {
    "id": "77c7e591-7d7b-4d92-8f61-d5bb03af5dd7"
   },
   "source": [
    "### Data processing <a class=\"anchor\" id=\"data\"></a>\n",
    "\n",
    "Copied from part 1\n",
    "\n",
    "You'll either need to download the [imdb review data](https://ai.stanford.edu/~amaas/data/sentiment/) and save it to this directory OR download the [processed data](https://drive.google.com/file/d/1oN_fO91IBkDHD_u6WXiUCvhhyNexQDJq/view?usp=sharinghttps://drive.google.com/file/d/1oN_fO91IBkDHD_u6WXiUCvhhyNexQDJq/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c4ac0-5a90-49ef-b03b-378932d13c9a",
   "metadata": {
    "id": "9b3c4ac0-5a90-49ef-b03b-378932d13c9a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # processing the original data into DataFrame\n",
    "# # here for reference, don't need to run this if you're using reviews.pkl.gz\n",
    "# source_path = Path('./aclImdb/')\n",
    "# #neg_files = source_path.glob('./*/neg/*.txt')\n",
    "# #pos_files = source_path.glob('./*/pos/*.txt')\n",
    "# all_files = []\n",
    "# for f in source_path.glob('./*/*/*.txt'):\n",
    "#     filename = f.as_posix()\n",
    "#     if 'unsup' not in filename:\n",
    "#         # split up into useful components\n",
    "#         _, split, sent, idx = filename.split('/')\n",
    "#         idx = int(idx.split('_')[0])\n",
    "#         all_files.append([idx, split, sent, f.read_text()])\n",
    "# review_df = pd.DataFrame(all_files)\n",
    "# review_df.columns = ['idx', 'split', 'label', 'text']\n",
    "# # some minor html cruft is in here\n",
    "# review_df['text'] = review_df['text'].str.replace('<br /><br />', '')\n",
    "# review_df = review_df.to_pickle('reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f61ea-8e62-4d21-8f5a-6e3eb1bed2d3",
   "metadata": {
    "id": "e28f61ea-8e62-4d21-8f5a-6e3eb1bed2d3"
   },
   "outputs": [],
   "source": [
    "# can skip here if you already have reviews.pkl.gz\n",
    "review_df = pd.read_pickle('reviews.pkl.gz')\n",
    "review_df['label'] = review_df['label'] == 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f56964-2e4a-45bb-89d9-1da65ac6307a",
   "metadata": {
    "id": "88f56964-2e4a-45bb-89d9-1da65ac6307a"
   },
   "outputs": [],
   "source": [
    "# copied from part 1: using the same train/test split\n",
    "seed = 37\n",
    "np.random.seed(seed)\n",
    "pct_train = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_df['text'],\n",
    "    review_df['label'], train_size=pct_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qWn_t_XRLPpb",
   "metadata": {
    "id": "qWn_t_XRLPpb"
   },
   "outputs": [],
   "source": [
    "# you may need to restart after this in Collab\n",
    "!pip install spacy-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cSe1LvjvLmte",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSe1LvjvLmte",
    "outputId": "5eaa8d28-472f-4eed-eff2-e7a1582dc7af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "em-MR4WcaeeR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "em-MR4WcaeeR",
    "outputId": "a2b0d81e-bbf5-4bbe-a50d-1f6e330a2554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bagging_to_bert'...\n",
      "remote: Enumerating objects: 72, done.\u001b[K\n",
      "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
      "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
      "remote: Total 72 (delta 36), reused 53 (delta 17), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (72/72), 27.39 MiB | 11.39 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b revised_2023 https://github.com/bpben/bagging_to_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "T6wGvK15ajhd",
   "metadata": {
    "id": "T6wGvK15ajhd"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, labels, name):\n",
    "  \n",
    "    # initialize spaCy's DocBin format (easier use with spaCy pipeline)\n",
    "    db = DocBin()\n",
    "    output_path = f'{name}.spacy'\n",
    "    data_tuples = zip(text, labels)\n",
    "    # pipe is slightly faster than individually processing each\n",
    "    for doc, label in nlp.pipe(data_tuples, as_tuples=True):\n",
    "      # store the labels in the document's .cat attribute\n",
    "      if label == 'pos':\n",
    "            doc.cats['pos'] = True\n",
    "            doc.cats['neg'] = False\n",
    "        else:\n",
    "            doc.cats['pos'] = False\n",
    "            doc.cats['neg'] = True\n",
    "        db.add(doc)\n",
    "    # save the DocBin\n",
    "    db.to_disk(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "W-QB_EmLbEvv",
   "metadata": {
    "id": "W-QB_EmLbEvv"
   },
   "outputs": [],
   "source": [
    "# spaCy default corpus reader has certain expectations about format\n",
    "review_df = pd.read_pickle(\n",
    "    '/content/drive/MyDrive/talks/odsc_2023/reviews.pkl.gz')\n",
    "# copied from part 1: want to use the same train/test split\n",
    "seed = 37\n",
    "np.random.seed(seed)\n",
    "pct_train = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_df['text'],\n",
    "    review_df['label'], train_size=pct_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "w4kXX9W06JaS",
   "metadata": {
    "id": "w4kXX9W06JaS"
   },
   "outputs": [],
   "source": [
    "# running the preprocessing on each split\n",
    "preprocess(X_train, y_train, 'train')\n",
    "preprocess(X_test, y_test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c795cb-66e0-48d5-a28a-4476ca1cef64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85c795cb-66e0-48d5-a28a-4476ca1cef64",
    "outputId": "1a114268-3cd7-46c7-9929-7e1ba2189c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: example_model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ------------  ----------  ------\n",
      "  0       0           0.00          0.25       35.15    0.35\n",
      "  0     200           0.00         50.14       36.27    0.36\n",
      "  0     400           0.00         40.94       76.70    0.77\n",
      "  0     600           0.01         33.34       70.19    0.70\n",
      "  0     800           0.03         36.88       76.52    0.77\n",
      "  0    1000           0.06         41.10       82.04    0.82\n",
      "  0    1200           0.05         32.34       82.00    0.82\n",
      "  0    1400           0.05         28.28       83.54    0.84\n",
      "  0    1600           0.07         33.07       83.66    0.84\n",
      "  0    1800           0.09         28.94       84.20    0.84\n",
      "  0    2000           0.09         30.79       74.64    0.75\n",
      "  0    2200           0.16         29.76       85.45    0.85\n",
      "  0    2400           0.13         32.45       82.69    0.83\n",
      "  0    2600           0.10         21.63       78.18    0.78\n",
      "  0    2800           0.15         31.64       84.75    0.85\n",
      "  0    3000           0.11         23.50       85.96    0.86\n",
      "  0    3200           0.18         31.92       85.69    0.86\n",
      "  0    3400           0.18         27.92       83.98    0.84\n",
      "  0    3600           0.16         26.11       80.00    0.80\n",
      "  0    3800           0.09         15.93       83.99    0.84\n",
      "  0    4000           0.21         28.63       86.42    0.86\n",
      "  0    4200           0.18         25.39       78.23    0.78\n",
      "  0    4400           0.17         20.11       83.73    0.84\n",
      "  0    4600           0.21         27.61       85.75    0.86\n",
      "  0    4800           0.25         27.27       87.99    0.88\n",
      "  0    5000           0.19         25.19       85.43    0.85\n",
      "  0    5200           0.36         29.34       85.07    0.85\n",
      "  0    5400           0.28         30.86       86.82    0.87\n",
      "  0    5600           0.26         27.79       84.79    0.85\n",
      "  0    5800           0.25         27.34       85.85    0.86\n",
      "  0    6000           0.27         23.30       82.96    0.83\n",
      "  0    6200           0.22         24.79       86.42    0.86\n",
      "  0    6400           0.23         26.50       86.02    0.86\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "example_model/model-last\n"
     ]
    }
   ],
   "source": [
    "from spacy.cli.train import train\n",
    "\n",
    "# can override config info with overrides\n",
    "# the tutorial config file doesn't have the paths for train/dev corpora\n",
    "# going to just run this for a few epochs, see how it works\n",
    "train(\"bagging_to_bert/spacy_materials/config_trf.cfg\",\n",
    "      output_path='example_model',\n",
    "      overrides={\"paths.train\": \"train.spacy\", \n",
    "                 \"paths.dev\": \"test.spacy\",\n",
    "                 \"training.max_epochs\": 1},\n",
    "      use_gpu = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qdmGkvsPQoEu",
   "metadata": {
    "id": "qdmGkvsPQoEu"
   },
   "outputs": [],
   "source": [
    "# load the best version of the model\n",
    "m = spacy.load('/content/drive/MyDrive/talks/odsc_2023/trained_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "yFmuwUE6-xP9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFmuwUE6-xP9",
    "outputId": "6fcf4123-d20b-4e5e-b9fe-9e3bb4a0443d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': 0.9958682060241699, 'neg': 0.004131876397877932}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the outputs from running a simple example\n",
    "m('This movie is great').cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cUaNYxfHAECZ",
   "metadata": {
    "id": "cUaNYxfHAECZ"
   },
   "source": [
    "SpaCy has its own evaluation capabilities, but for comparison's sake, let's use the same evaluation approach we did with out other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ih7n0wGxABGa",
   "metadata": {
    "id": "Ih7n0wGxABGa"
   },
   "outputs": [],
   "source": [
    "# if you're interested in trying out spacy's own evaluate\n",
    "#from spacy.cli.evaluate import evaluate\n",
    "#evaluate(model='./example_model/model-best/', data_path='test.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I6HiG41AAeSH",
   "metadata": {
    "id": "I6HiG41AAeSH"
   },
   "outputs": [],
   "source": [
    "# get the predicted category from the model\n",
    "pred = np.array([max(d.cats, key=d.cats.get) for d in m.pipe(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9WIqefqOBF1Y",
   "metadata": {
    "id": "9WIqefqOBF1Y"
   },
   "outputs": [],
   "source": [
    "print(f'accuracy: {np.where(pred == y_test)[0].shape[0]/y_test.shape[0]}')\n",
    "print(\n",
    "    classification_report(y_pred=pred,\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cfc03-000a-4381-a353-2778f97b2a36",
   "metadata": {
    "id": "219cfc03-000a-4381-a353-2778f97b2a36"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746651a7-efe3-4098-a9c9-50d971baa113",
   "metadata": {
    "id": "746651a7-efe3-4098-a9c9-50d971baa113"
   },
   "source": [
    "### LSTM <a class=\"anchor\" id=\"lstm\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34655d0-8532-4ad3-9a46-02f9b2b390cc",
   "metadata": {
    "id": "a34655d0-8532-4ad3-9a46-02f9b2b390cc"
   },
   "outputs": [],
   "source": [
    "class SentLSTM(nn.Module):\n",
    "# adapted from https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size):\n",
    "        super(SentLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to sentiment space\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "        # sigmoid activiation\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward pass of nn\n",
    "        batch_size = x.shape[0]\n",
    "        # this is fit during training\n",
    "        embeds = self.word_embeddings(x)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # from lstm space to prediction space\n",
    "        pred_space = self.fc(lstm_out)\n",
    "        out = self.sigmoid(pred_space)\n",
    "        # reshape - want to get the prediction at end of seq\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out\n",
    "\n",
    "def doc_to_index(docs, vocab, tokenizer, unknown=1):\n",
    "    # transform docs into series of indices\n",
    "    docs_idxs = []\n",
    "    for d in docs:\n",
    "        w_idxs = []\n",
    "        d_tokenized = tokenizer(d)\n",
    "        for w in d_tokenized:\n",
    "            if w in vocab:\n",
    "                w_idxs.append(vocab[w])\n",
    "            else:\n",
    "                # unknown if not in vocab\n",
    "                w_idxs.append(unknown)\n",
    "        docs_idxs.append(w_idxs)\n",
    "    return(docs_idxs)\n",
    "\n",
    "def pad_sequence(seqs, seq_len=200):\n",
    "    # function for adding padding to ensure all seq same length\n",
    "    features = np.zeros((len(seqs), seq_len),dtype=int)\n",
    "    for i, seq in enumerate(seqs):\n",
    "        if len(seq) != 0:\n",
    "            features[i, -len(seq):] = np.array(seq)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59664271-7328-4d64-a067-c9347adf70c2",
   "metadata": {
    "id": "59664271-7328-4d64-a067-c9347adf70c2"
   },
   "outputs": [],
   "source": [
    "# need to adapt vocab, leave space for padding\n",
    "tfidf = TfidfVectorizer(stop_words='english', min_df=0.01)\n",
    "tfidf.fit(X_train)\n",
    "vocab = tfidf.vocabulary_\n",
    "tokenizer = tfidf.build_tokenizer()\n",
    "# need to add \"special\" tokens\n",
    "vocab = dict([(v, vocab[v]+2) for v in vocab])\n",
    "vocab['_UNK'] = 1\n",
    "vocab['_PAD'] = 0\n",
    "# from documents to vocab index\n",
    "parsed_train = doc_to_index(X_train, vocab, tokenizer)\n",
    "padded_train = pad_sequence(parsed_train)\n",
    "parsed_test = doc_to_index(X_test, vocab, tokenizer)\n",
    "padded_test = pad_sequence(parsed_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df50502-d9f1-4704-8210-ebeeaa872bdb",
   "metadata": {
    "id": "6df50502-d9f1-4704-8210-ebeeaa872bdb"
   },
   "outputs": [],
   "source": [
    "# construct datasets for loading by PyTorch\n",
    "train_data = TensorDataset(torch.from_numpy(padded_train), \n",
    "                           torch.from_numpy(y_train.values))\n",
    "test_data = TensorDataset(torch.from_numpy(padded_test), \n",
    "                          torch.from_numpy(y_test.values))\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,\n",
    "                         drop_last=True) # this is to keep the size consistent\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size,\n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37691ceb-8429-43f6-a11a-9a4e55bfd602",
   "metadata": {
    "id": "37691ceb-8429-43f6-a11a-9a4e55bfd602"
   },
   "outputs": [],
   "source": [
    "# binary problem, single output\n",
    "model_params = {'output_size': 1,\n",
    "               'hidden_dim': 512,\n",
    "               'embedding_dim': 400,\n",
    "               'vocab_size': len(vocab)}\n",
    "model = SentLSTM(**model_params)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcbf0b2-a9ee-4511-a568-ea56767d4900",
   "metadata": {
    "id": "7bcbf0b2-a9ee-4511-a568-ea56767d4900"
   },
   "outputs": [],
   "source": [
    "# learning rate\n",
    "lr=0.005\n",
    "# binary cross-entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# increasing this will make the training take a while on CPU\n",
    "epochs = 1\n",
    "counter = 0\n",
    "print_every = 5\n",
    "# gradient clipping: https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # sets gradients to zero for each batch\n",
    "        model.zero_grad()\n",
    "        output = model(inputs)\n",
    "        # pred vs actual\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print progress\n",
    "        if counter%print_every == 0:\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in test_loader:\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out = model(inp)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fb9f2-0a0c-4530-a898-c8cc3d36f7a8",
   "metadata": {
    "id": "214fb9f2-0a0c-4530-a898-c8cc3d36f7a8"
   },
   "outputs": [],
   "source": [
    "# pytorch LSTM model\n",
    "model.load_state_dict(torch.load('./state_dict.pt'))\n",
    "model.eval()\n",
    "pred_collect = np.array([])\n",
    "eval_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "# eval mode\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in eval_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output = model(inputs)\n",
    "        # takes output, rounds to 0/1\n",
    "        pred = torch.round(output.squeeze())\n",
    "        pred_collect = np.concatenate([\n",
    "          pred_collect,\n",
    "          pred.cpu().numpy()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd2316-e1c8-4b49-b790-3a856c80ef2d",
   "metadata": {
    "id": "e4bd2316-e1c8-4b49-b790-3a856c80ef2d"
   },
   "outputs": [],
   "source": [
    "print(f'accuracy: {np.where(pred_collect == y_test)[0].shape[0]/y_test.shape[0]}')\n",
    "print(\n",
    "    classification_report(y_pred=pred_collect,\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9536ef-ae86-406f-92f2-8ef3fb07db18",
   "metadata": {
    "id": "1d9536ef-ae86-406f-92f2-8ef3fb07db18"
   },
   "source": [
    "### BERT <a class=\"anchor\" id=\"bert!pip install transformers\"></a>\n",
    "From [HF tutorials](https://huggingface.co/blog/sentiment-analysis-python).  The sentiment analysis pipeline packages together the tokenizer and the BERT model with a classification layer.  The default pipeline uses this [distilBERT model](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d48a465-92d4-44ab-9fb6-8eeefb3971ea",
   "metadata": {
    "id": "5d48a465-92d4-44ab-9fb6-8eeefb3971ea"
   },
   "outputs": [],
   "source": [
    "# this will need to be run if you don't already have this package\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60eb292-ff25-4f5e-bf00-a7c8672c758f",
   "metadata": {
    "id": "c60eb292-ff25-4f5e-bf00-a7c8672c758f"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3e58f-5b03-41a2-92f7-69beb3fc0aee",
   "metadata": {
    "id": "24b3e58f-5b03-41a2-92f7-69beb3fc0aee"
   },
   "outputs": [],
   "source": [
    "# some manipulations for speed and to play nice with BERT\n",
    "bert_pred = sentiment_pipeline(X_test.apply(lambda x: x).head(n=50).tolist())\n",
    "bert_pred = [p['label']=='POSITIVE' for p in bert_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afb1f9-1e29-463d-b4f9-50dcdd0c2af8",
   "metadata": {
    "id": "25afb1f9-1e29-463d-b4f9-50dcdd0c2af8"
   },
   "outputs": [],
   "source": [
    "np.where(bert_pred == y_test[:50])\n",
    "print(f'accuracy: {np.where(bert_pred == y_test[:50])[0].shape[0]/50}')\n",
    "print(\n",
    "    classification_report(y_pred=bert_pred,\n",
    "                          y_true=y_test[:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba778396-c395-4364-a2dc-4aab7d274765",
   "metadata": {
    "id": "ba778396-c395-4364-a2dc-4aab7d274765"
   },
   "source": [
    "There it is - you've leveraged a cutting edge model to do sentiment analysis! This performance is pretty good, but our count vectors actually did a few points better.  Maybe there's an opportunity to fine-tune the BERT model specifically to the IMDB review dataset.  Let's try it.\n",
    "\n",
    "** IN PROGRESS **\n",
    "\n",
    "Still have been having some issues - performance is conspicuously low.  Use with caution.\n",
    "\n",
    "NOTE: This takes some time to run, even with the Collab GPU.  You might want to experiment on subsets of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d59127-dd97-4389-b000-0be0a48f7a95",
   "metadata": {
    "id": "f5d59127-dd97-4389-b000-0be0a48f7a95"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# WIP - \"num_labels\" seems like it should be 1, have seen 2 (pos/neg)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",  num_labels=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65798282-94d0-4e14-ac77-b19420828f9a",
   "metadata": {
    "id": "65798282-94d0-4e14-ac77-b19420828f9a"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    return tokenizer(example, truncation=True)\n",
    "\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    # comes from https://huggingface.co/transformers/v3.4.0/custom_datasets.html\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.astype(float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# we will subsample because it makes this faster\n",
    "n = 1000\n",
    "tokenized_train = tokenizer(X_train.tolist()[:n], \n",
    "                            truncation=True, padding=True)\n",
    "tokenized_test = tokenizer(X_test.tolist()[:n], \n",
    "                           truncation=True, padding=True)\n",
    "\n",
    "train_dataset = IMDbDataset(tokenized_train, y_train.values[:n])\n",
    "test_dataset = IMDbDataset(tokenized_test, y_test.values[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c0157-ed4b-434d-bafa-215c8a87f35a",
   "metadata": {
    "id": "1d3c0157-ed4b-434d-bafa-215c8a87f35a"
   },
   "outputs": [],
   "source": [
    "# using HF's trainer\n",
    "# again, this comes from https://huggingface.co/transformers/v3.4.0/custom_datasets.html\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir='./',\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=5,\n",
    "   weight_decay=0.01,\n",
    "   save_strategy=\"epoch\",\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=train_dataset,\n",
    "   eval_dataset=test_dataset,\n",
    "   tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec1c8f-f444-4b02-88bb-0fb6b94d23bf",
   "metadata": {
    "id": "07ec1c8f-f444-4b02-88bb-0fb6b94d23bf"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1068ef-f95d-464e-af73-184825f79c21",
   "metadata": {
    "id": "ba1068ef-f95d-464e-af73-184825f79c21"
   },
   "outputs": [],
   "source": [
    "# hacky - moving back to cpu where the other data is located\n",
    "# HF suggests a \"prediction\" Trainer\n",
    "m = model.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197342ef-d267-4ba4-9a27-73e25f369e92",
   "metadata": {
    "id": "197342ef-d267-4ba4-9a27-73e25f369e92"
   },
   "outputs": [],
   "source": [
    "# same parameters we trained with\n",
    "classifier_pipeline = pipeline(task=\"text-classification\", \n",
    "                               model=m, tokenizer=tokenizer,\n",
    "                               truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e09bf6-cf5f-4490-afcd-ec322b973041",
   "metadata": {
    "id": "55e09bf6-cf5f-4490-afcd-ec322b973041"
   },
   "outputs": [],
   "source": [
    "# pred outputs slightly different from sentiment pipeline\n",
    "bert_pred = classifier_pipeline(X_test.tolist())\n",
    "bert_pred = [p['score']>0.5 for p in bert_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b4fcd-3b7b-43f5-85a9-45d7d424dd54",
   "metadata": {
    "id": "a23b4fcd-3b7b-43f5-85a9-45d7d424dd54"
   },
   "outputs": [],
   "source": [
    "# performance is pretty bad, even after 5 epochs\n",
    "print(f'accuracy: {np.where(bert_pred == y_test)[0].shape[0]/len(y_test)}')\n",
    "print(\n",
    "    classification_report(y_pred=bert_pred,\n",
    "                          y_true=y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "spacy3",
   "language": "python",
   "name": "spacy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
