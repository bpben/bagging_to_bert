{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c2486-cf28-4e32-9b85-3caf4296a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb78f4-b61c-4e56-a1e2-153fb0482523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7e591-7d7b-4d92-8f61-d5bb03af5dd7",
   "metadata": {},
   "source": [
    "## Bagging to BERT: Count vectors for sentiment analysis\n",
    "This notebook accompanies the ODSC blog post introducing the Bagging to BERT workshop.# processing the original data into DataFrame\n",
    "here for reference, don't need to run this if you're using reviews.pkl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9b3c4ac0-5a90-49ef-b03b-378932d13c9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # processing the original data into DataFrame\n",
    "# # here for reference, don't need to run this if you're using reviews.pkl.gz\n",
    "# source_path = Path('./aclImdb/')\n",
    "# #neg_files = source_path.glob('./*/neg/*.txt')\n",
    "# #pos_files = source_path.glob('./*/pos/*.txt')\n",
    "# all_files = []\n",
    "# for f in source_path.glob('./*/*/*.txt'):\n",
    "#     filename = f.as_posix()\n",
    "#     if 'unsup' not in filename:\n",
    "#         # split up into useful components\n",
    "#         _, split, sent, idx = filename.split('/')\n",
    "#         idx = idx.split('_')[0]\n",
    "#         all_files.append([idx, split, sent, f.read_text()])\n",
    "# review_df = pd.DataFrame(all_files)\n",
    "# review_df.columns = ['idx', 'split', 'label', 'text']\n",
    "# # some minor html cruft is in here\n",
    "# review_df['text'] = review_df['text'].str.replace('<br /><br />', '')\n",
    "# # saving this down as a gzipped pickle\n",
    "# review_df.to_pickle('reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24343773-3f76-421a-b75d-2ecd5e51d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the review pickle\n",
    "review_df = pd.read_pickle('reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db840c0f-9f6d-4058-9913-356eb700dcd0",
   "metadata": {},
   "source": [
    "### Word counts\n",
    "A very basic way to use a sanitized list of tokens is to do a word count. This unlocks a lot of insights right off and is an important step in exploratory data analysis in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2646a7d-b0f4-406d-bb68-7f5351b425b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a positive and negative review for examples\n",
    "neg_review = review_df[review_df.label=='neg'].iloc[0]['text']\n",
    "pos_review = review_df[review_df.label=='pos'].iloc[0]['text']\n",
    "print('Negative\\n', neg_review, '\\n')\n",
    "print('Positive\\n', pos_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee60e2b-b1b5-4342-9e7e-8e0e3f17538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base python word count - split on whitespace, use Counter object)\n",
    "neg_review = review_df[review_df.label=='neg'].iloc[0]['text']\n",
    "print(Counter(neg_review.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c7f82-7e21-42a1-9f70-0c97345ab36a",
   "metadata": {},
   "source": [
    "Already see some things that need to be considered; capitalization treats \"The\" and \"the\" differently, words like \"the\" and \"it\" dominate counts.\n",
    "\n",
    "Luckily, scikit-learn's CountVectorizer allows for simple preprocessing like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868f067-62e5-4227-9e81-76485ec7cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn's countvectorizer\n",
    "count = CountVectorizer()\n",
    "neg_vec = count.fit_transform([neg_review])\n",
    "neg_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b990345-6215-4e55-845e-53ad8d5c5e80",
   "metadata": {},
   "source": [
    "`CountVectorizer` outputs a sparse matrix by default.  We can convert that to a normal numpy array and stitch it together with the vocabulary from the `fit()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628123c-2f0a-48b5-afa3-faf6284f60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    dict(zip(count.get_feature_names_out(), \n",
    "             neg_vec.toarray().flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c23b3-8d69-4a1b-b2e8-726f88eeb977",
   "metadata": {},
   "source": [
    "We can see the defaults have already done some amount of cleaning for us.\n",
    "\n",
    "### Deterministic Approach\n",
    "\n",
    "Let's try a deterministic approach, using word counts and a list of \"positive\" vs \"negative\" words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c4e13-03bf-4110-b15a-c128c12c7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = [\"good\", \"great\", \"like\", \"loved\"]\n",
    "neg_words = [\"bad\", \"awful\", \"dislike\", \"hated\"]\n",
    "\n",
    "# we're going to use this train/test split throughout\n",
    "# we'll also use this seed for consistency\n",
    "# NOTE: Usually you'll want to do a separate validation set when choosing models/featuresets!\n",
    "seed = 37\n",
    "np.random.seed(seed)\n",
    "pct_train = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_df['text'],\n",
    "    review_df['label'], train_size=pct_train)\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "train_vecs = cv.fit_transform(X_train).toarray()\n",
    "feats = cv.get_feature_names_out()\n",
    "pos_idxs = np.where(np.isin(feats, pos_words))[0]\n",
    "neg_idxs = np.where(np.isin(feats, neg_words))[0]\n",
    "train_det_score = train_vecs[:, pos_idxs].sum(1) - train_vecs[:, neg_idxs].sum(1)\n",
    "# easier for group-level score\n",
    "train_det_score = pd.Series(train_det_score, index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c8284-bb84-46e1-982e-928e140eeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our threshold - the average score for negative, that or below = negative\n",
    "neg_thresh = train_det_score.groupby(review_df['label'].loc[X_train.index]).mean()['neg']\n",
    "test_vecs = cv.transform(X_test)\n",
    "test_det_score = test_vecs[:, pos_idxs].sum(1) - test_vecs[:, neg_idxs].sum(1)\n",
    "det_pred = test_det_score>neg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea3fdf-6cb4-4602-a384-dd05460ac21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(y_pred=det_pred,\n",
    "                          y_true=y_test=='pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f69c5-72b7-4ae9-8ed8-969818832c07",
   "metadata": {},
   "source": [
    "### Count Vector + Logistic Regression\n",
    "Here we try a count vector with Logistic Regression.  This alleviates the need for chosing an arbitrary set of terms and arbitrary threshold as above.\n",
    "\n",
    "Here I use scikit-learn's [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) functionality.  I won't try and explain that here, the docs do a much better job than I can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a9d696-97ba-415d-84d2-503844edf3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english')\n",
    "\n",
    "count_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", count),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952acf7e-5a15-4bb8-88d1-258a634e5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "count_pipeline.fit(X_train, y_train)\n",
    "count_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d9f7f-53b2-4cbb-92e6-2d5bac6dcf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(y_pred=count_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30256a1-982a-4aee-877c-7a7045580aa2",
   "metadata": {},
   "source": [
    "This is actually really good! 90% of the time we're predicting the right class with this model.  But can we do...better?\n",
    "\n",
    "### TF-IDF\n",
    "One thing we notice with count vectors is that all words are being counted the same.  We might want to use a weighting scheme to ensure that words that are more informative about the content are flagged as more important.  One weighting scheme is Term Frequency - Inverse Document Frequency (TF-IDF).\n",
    "\n",
    "Take as an example some kind of simplistic movie reviews.  We can already tell which words are most relevant to the specific content of each review (i.e. \"good\", \"bad\", \"great\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e0955-d159-4d27-8508-c1a5645a6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['The movie was good',\n",
    "        'The movie was bad',\n",
    "        'The movie was great']\n",
    "\n",
    "cv = CountVectorizer()\n",
    "vecs = cv.fit_transform(docs).toarray()\n",
    "# we'll use pandas DF for easier display\n",
    "pd.DataFrame(vecs, columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d93d3-aa56-4599-bd57-bd4e12232445",
   "metadata": {},
   "source": [
    "You'll notice that `vecs` contains the term frequencies.  If we use sklearn's `TfidfVectorizer`, it will calculate those term counts and then multiply them by the Inverse Document Frequency (IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3611e-8860-411c-b297-e9d2eedca714",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "# we'll use pandas DF for easier display\n",
    "tfidf_vecs = tfidf.fit_transform(docs).toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_vecs, columns=tfidf.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464164b-5882-48d7-8bb9-f48008ca8d92",
   "metadata": {},
   "source": [
    "You can see that the discriminative words have higher weight than the non-discriminative words.  \n",
    "\n",
    "It's worth noting here - in terms of \"separability\", having 0 v 1 (count of \"good\" vs count of \"bad\") might actually be better.  But these are highly curated examples - you can imagine cases where good and bad descriptive terms are mixed in a review, you want to capture the words that describe better the \"aboutness\" of the review.  (Think: \"This movie was not bad, it was good!\")\n",
    "\n",
    "Now let's fit our regression as above with TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f28bdf-371d-4dd7-a25b-63376f3f76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use binary here to handle longer reviews\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tfidf_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", tfidf),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f2b41-18ed-4fab-adee-d5b7bd44c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "tfidf_pipeline.fit(X_train, y_train)\n",
    "tfidf_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0c34d-00cb-4204-a538-8efc61755bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(y_pred=tfidf_pipeline.predict(X_test),\n",
    "                          y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5b18b-9e54-4ba9-afd3-9a63318aa93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the coefficients on the LR for each model\n",
    "word_feats = tfidf_pipeline['preprocessor'].get_feature_names_out()\n",
    "# this is the same as the count pipeline\n",
    "#all(word_feats == count_pipeline['preprocessor'].get_feature_names_out())\n",
    "# get the largest by magnitude, stitch together to compare\n",
    "top = 5\n",
    "top_tfidf = np.argsort(np.abs(tfidf_pipeline['model'].coef_.flatten()))[-top:]\n",
    "top_count = np.argsort(np.abs(count_pipeline['model'].coef_.flatten()))[-top:]\n",
    "# top\n",
    "coef_df = pd.DataFrame([\n",
    "    word_feats,\n",
    "    tfidf_pipeline['model'].coef_.flatten(),\n",
    "    count_pipeline['model'].coef_.flatten()],\n",
    "    index=['word', 'tfidf', 'count']).T\n",
    "# normalize result for compare\n",
    "coef_df['tfidf'] = (coef_df['tfidf'] - coef_df['tfidf'].mean())/coef_df['tfidf'].std()\n",
    "coef_df['count'] = (coef_df['count'] - coef_df['count'].mean())/coef_df['count'].std()\n",
    "coef_df.loc[np.unique(np.concatenate([top_tfidf, top_count]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0d90b-ec5f-46ff-a3da-6684ad26778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples where there's disagreement\n",
    "tfidf_pred = tfidf_pipeline.predict_proba(X_train)[:, 1]\n",
    "count_pred = count_pipeline.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456f39f-b53c-4293-aadf-a4725db61123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most interesting are where there's the largest disagreement\n",
    "top_disagree_idx = np.argsort(np.abs(tfidf_pred - count_pred))[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f8ac0-64a1-43c4-aeac-ba6488050b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble in df\n",
    "compare_df = pd.DataFrame([tfidf_pred, count_pred, y_train, X_train],\n",
    "            index=['tfidf_pred', 'count_pred', 'label', 'text']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb8a7c-bb7c-413f-8540-cdcc24233e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df.loc[top_disagree_idx].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b549a-7bed-4879-b4c1-39ff6a278272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2231a0d4-dc4c-40b2-8d64-e9a23b2b6134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3570f38b-f758-458f-b1ef-b7413ef5e9c4",
   "metadata": {},
   "source": [
    "### Word embeddings\n",
    "Our next approach is to include context in the word-level representations.  We'll be bringing SpaCy into the mix here, particularly their \"medium\" English web model, which uses GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb1334-e39e-4ee3-abd0-8c91acbbe406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abdfd44-0837-43a5-8a84-4d27bb70fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b746a-3b95-4519-adfb-b48b111964fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GloveVectorizer(BaseEstimator, TransformerMixin):\n",
    "    # this is a custom document transformer for use in the scikit-learn pipeline\n",
    "    def __init__(self, vectorizer):\n",
    "        self.vectorizer = vectorizer\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        vocab = self.vectorizer.vocabulary_\n",
    "        self.vocab_glove = np.zeros(shape=(len(vocab), 300))\n",
    "        for token, idx in vocab.items():\n",
    "            self.vocab_glove[idx] = nlp(token).vector\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = self.vectorizer.transform(X).toarray()\n",
    "        sum_words = (X_transformed.sum(1)).reshape(-1, 1)\n",
    "        glove_vecs = (X_transformed.dot(self.vocab_glove))/sum_words\n",
    "        return glove_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d405e-ebaf-49f9-b83c-a8794ab4abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use binary here to handle longer reviews\n",
    "count = CountVectorizer(stop_words='english', min_df=0.01, binary=False)\n",
    "glove = GloveVectorizer(count)\n",
    "\n",
    "glove_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", glove),\n",
    "          ('model', LogisticRegression(max_iter=500, solver='liblinear'))]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b10c82b-b418-4f60-9f65-e0208bd3097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "glove_pipeline.fit(X_train, y_train)\n",
    "glove_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503d51d-d428-4bff-91df-264379d324fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy3",
   "language": "python",
   "name": "spacy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
